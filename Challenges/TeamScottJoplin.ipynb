{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Key estimation challenge\n",
    "\n",
    "This challenge was about finding out which key a piece was written in. The input was a set of .midi files containing performed pieces, and the output was a file that assigned each piece a key.\n",
    "\n",
    "To solve this problem, a recurrent neural network (RNN) was used as described by Liu et al. in [\"PERFORMANCE MIDI-TO-SCORE CONVERSION BY\n",
    "NEURAL BEAT TRACKING\"](https://www.turing.ac.uk/sites/default/files/2022-09/midi_quantisation_paper_ismir_2022_0.pdf). This paper is also explained in a [YouTube-Video](https://www.youtube.com/watch?v=yumxXCYSgbY) and their code is openly available at [GitHub](https://github.com/cheriell/PM2S).\n",
    "\n",
    "We altered their code base to work with the data set given to us and to produce output in the correct format.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9c6872a2e122ee9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Data\n",
    "\n",
    "At first, we have to load in our data in the format that is accepted by the RNN. Every piece should be transformed into a list of notes represented of a tuple (pitch, onset_sec, duration_sec, velocity). As the RNN is able to handle key signature changes, the label is not a single key, but a list of key signature changes. In our case there is always just one key signature change at the beginning of the piece."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7623616d29d11353"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Augmentation\n",
    "\n",
    "Before we create the data set class, we have to take a look at data augmentation.\n",
    "\n",
    "An easy way to upscale the size of the given data set to prevent overfitting is augmenting the data. In this case, the tempo of the piece can be changed by scaling the onset and duration of every note by a given factor. Even more importantly, the piece can be transposed by changing the pitch of all notes simultaneously. When doing this, the key label also has to be changed, because a piece in B major that is transposed by a semitone upwards is now in C major. Please note that in the original code, there was an error that caused keys to be shifted incorrectly, causing the label of a piece in B major to be set to C minor instead of C major when pitching up by a semitone."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "436509bddd2d1a53"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "class DataAugmentation:\n",
    "    def __init__(self,\n",
    "                 tempo_change_prob=1.0,\n",
    "                 tempo_change_range=(0.8, 1.2),\n",
    "                 pitch_shift_prob=1.0,\n",
    "                 pitch_shift_range=(-6, 6)):\n",
    "\n",
    "        self.tempo_change_prob = tempo_change_prob\n",
    "        self.tempo_change_range = tempo_change_range\n",
    "        self.pitch_shift_prob = pitch_shift_prob\n",
    "        self.pitch_shift_range = pitch_shift_range\n",
    "\n",
    "    def __call__(self, note_sequence, annotations):\n",
    "        # tempo change\n",
    "        if random.random() < self.tempo_change_prob:\n",
    "            note_sequence, annotations = self.tempo_change(note_sequence, annotations)\n",
    "\n",
    "        # pitch shift\n",
    "        if random.random() < self.pitch_shift_prob:\n",
    "            note_sequence, annotations = self.pitch_shift(note_sequence, annotations)\n",
    "\n",
    "        return note_sequence, annotations\n",
    "\n",
    "    def tempo_change(self, note_sequence, annotations):\n",
    "        tempo_change_ratio = random.uniform(*self.tempo_change_range)\n",
    "        note_sequence[:, 1:3] *= 1 / tempo_change_ratio\n",
    "        annotations['time_signatures'][:, 0] *= 1 / tempo_change_ratio\n",
    "        annotations['key_signatures'][:, 0] *= 1 / tempo_change_ratio\n",
    "        return note_sequence, annotations\n",
    "\n",
    "    def pitch_shift(self, note_sequence, annotations):\n",
    "        shift = round(random.uniform(*self.pitch_shift_range))\n",
    "        note_sequence[:, 0] += shift\n",
    "\n",
    "        for i in range(len(annotations['key_signatures'])):\n",
    "            key = annotations['key_signatures'][i, 1]\n",
    "            minor_offset = 12 * (key // 12)\n",
    "            scale_offset = key - minor_offset\n",
    "\n",
    "            annotations['key_signatures'][i, 1] = minor_offset + (scale_offset + shift) % 12\n",
    "\n",
    "        return note_sequence, annotations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T19:08:27.786878100Z",
     "start_time": "2023-12-26T19:08:27.767920900Z"
    }
   },
   "id": "2de1ecd0a77543f8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Base Data Set\n",
    "\n",
    "As we use the same RNN for the key and meter estimation challenges, we have an abstract BaseDataSet for both of them. This data set holds the data and can then generate random batches to feed to the RNN for training."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddbc5141ea2f327c"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.insert(0, os.path.join(sys.path[0], '..'))\n",
    "import torch\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from pathlib import Path\n",
    "import partitura as pt\n",
    "\n",
    "class BaseDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, workspace, split):\n",
    "\n",
    "        # parameters\n",
    "        self.workspace = workspace\n",
    "        self.feature_folder = os.path.join(workspace, 'Dataset')\n",
    "        self.split = split\n",
    "\n",
    "        # Get metadata by split\n",
    "        self.metadata = pd.read_csv(os.path.join(self.feature_folder, 'key-meter_train_gt.txt'), delimiter=',')\n",
    "        self.metadata.reset_index(inplace=True)\n",
    "\n",
    "        # Get distinct pieces\n",
    "        self.piece2row = defaultdict(list)\n",
    "        for i, row in self.metadata.iterrows():\n",
    "            self.piece2row[row['filename']].append(i)\n",
    "        self.pieces = list(self.piece2row.keys())\n",
    "\n",
    "        # Initialise data augmentation\n",
    "        self.dataaug = DataAugmentation()\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.split == 'train' or self.split == 'all':\n",
    "            # constantly update 200 steps per epoch, not related to training dataset size\n",
    "            return batch_size * 200\n",
    "\n",
    "        elif self.split == 'valid':\n",
    "            # by istinct pieces in validation set\n",
    "            return batch_size * len(self.piece2row) // 10  # valid dataset size\n",
    "\n",
    "        elif self.split == 'test':\n",
    "            return len(self.metadata)\n",
    "\n",
    "    def _sample_row(self, idx):\n",
    "        # Sample one row from the metadata\n",
    "        if self.split == 'train' or self.split == 'all':\n",
    "            piece_id = random.choice(list(self.piece2row.keys()))   # random sampling by piece\n",
    "            row_id = random.choice(self.piece2row[piece_id])\n",
    "        elif self.split == 'valid':\n",
    "            piece_id = self.pieces[idx // batch_size]    # by istinct pieces in validation set\n",
    "            row_id = self.piece2row[piece_id][idx % batch_size % len(self.piece2row[piece_id])]\n",
    "        elif self.split == 'test':\n",
    "            row_id = idx\n",
    "        row = self.metadata.iloc[row_id]\n",
    "\n",
    "        return row\n",
    "\n",
    "    def _load_data(self, row):\n",
    "        # Get feature\n",
    "        p = pt.load_performance_midi(str(Path(self.feature_folder, row['filename'])))\n",
    "        note_array = p.note_array()\n",
    "        note_sequence = np.array(list(zip(note_array['pitch'], note_array['onset_sec'], note_array['duration_sec'], note_array['velocity'])))\n",
    "        annotations = {\n",
    "            'time_signatures': np.array([(0., row['ts_num'])]),\n",
    "            'key_signatures': np.array([(0., keyName2Number[row['key']])]),\n",
    "            'tempo': np.array([(0., row['tempo'])])\n",
    "        }\n",
    "\n",
    "        # Data augmentation\n",
    "        if self.split == 'train' or self.split == 'all':\n",
    "            note_sequence, annotations = self.dataaug(note_sequence, annotations)\n",
    "\n",
    "        # Randomly sample a segment that is at most max_length long\n",
    "        if self.split == 'train' or self.split == 'all':\n",
    "            start_idx = random.randint(0, len(note_sequence)-1)\n",
    "            end_idx = start_idx + max_length\n",
    "        elif self.split == 'valid':\n",
    "            start_idx, end_idx = 0, max_length  # validate on the segment starting with the first note\n",
    "        elif self.split == 'test':\n",
    "            start_idx, end_idx = 0, len(note_sequence)  # test on the whole note sequence\n",
    "\n",
    "        if end_idx > len(note_sequence):\n",
    "            end_idx = len(note_sequence)\n",
    "\n",
    "        note_sequence = note_sequence[start_idx:end_idx]\n",
    "\n",
    "        return note_sequence, annotations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T19:08:28.223565500Z",
     "start_time": "2023-12-26T19:08:28.185666300Z"
    }
   },
   "id": "3fcddc7e7db9e2f5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Key Signature Data Set\n",
    "\n",
    "To provide key estimation specific data, the abstract BaseDataSet is derived to return the correct label for every item in the dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2c8e33ee096ad8d"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from PM2S.constants import *\n",
    "\n",
    "\n",
    "class KeySignatureDataset(BaseDataset):\n",
    "\n",
    "    def __init__(self, workspace, split):\n",
    "        super().__init__(workspace, split)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        row = self._sample_row(idx)\n",
    "        note_sequence, annotations = self._load_data(row)\n",
    "\n",
    "        # Get model output data\n",
    "        key_signatures = annotations['key_signatures']\n",
    "\n",
    "        key_numbers = np.zeros(len(note_sequence)).astype(float)\n",
    "\n",
    "        for i in range(len(note_sequence)):\n",
    "            onset = note_sequence[i,1]\n",
    "            for ks in key_signatures:\n",
    "                if ks[0] > onset + tolerance:\n",
    "                    break\n",
    "                key_numbers[i] = ks[1] % keyVocabSize\n",
    "\n",
    "        # padding\n",
    "        length = len(note_sequence)\n",
    "        if length < max_length:\n",
    "            note_sequence = np.concatenate([note_sequence, np.zeros((max_length - length, 4))])\n",
    "            key_numbers = np.concatenate([key_numbers, np.zeros(max_length - length)])\n",
    "\n",
    "        return note_sequence, key_numbers, length"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T19:08:28.680393900Z",
     "start_time": "2023-12-26T19:08:28.654440500Z"
    }
   },
   "id": "5fadc9217034dd3a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data module\n",
    "Pytorch Lightning needs an implementation of a LightningDataModule for the training. It is needed for loading data differently during training, evaluating and testing."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c10e980cd41c414"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from PM2S.configs import *\n",
    "\n",
    "class Pm2sDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, args, feature='key_signature', full_train=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Parameters from input arguments\n",
    "        self.workspace = args.workspace\n",
    "        self.feature = feature\n",
    "        self.full_train = full_train\n",
    "\n",
    "    def _get_dataset(self, split):\n",
    "        if self.feature == 'key_signature':\n",
    "            dataset = KeySignatureDataset(self.workspace, split)\n",
    "        elif self.feature == 'time_signature':\n",
    "            dataset = TimeSignatureDataset(self.workspace, split) # will be important later\n",
    "        else:\n",
    "            raise ValueError('Unknown feature: {}'.format(self.feature))\n",
    "        return dataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        if self.full_train:\n",
    "            dataset = self._get_dataset(split='all')\n",
    "        else:\n",
    "            dataset = self._get_dataset(split='train')\n",
    "        sampler = torch.utils.data.sampler.RandomSampler(dataset)\n",
    "        dataloader = torch.utils.data.dataloader.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            sampler=sampler,\n",
    "            num_workers=0,\n",
    "            drop_last=True\n",
    "        )\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = self._get_dataset(split='valid')\n",
    "        sampler = torch.utils.data.sampler.SequentialSampler(dataset)\n",
    "        dataloader = torch.utils.data.dataloader.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            sampler=sampler,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=True\n",
    "        )\n",
    "        return dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataset = self._get_dataset(split='test')\n",
    "        sampler = torch.utils.data.sampler.SequentialSampler(dataset)\n",
    "        dataloader = torch.utils.data.dataloader.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=1,\n",
    "            sampler=sampler,\n",
    "            num_workers=0,\n",
    "            drop_last=False\n",
    "        )\n",
    "        return dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T19:08:29.138769Z",
     "start_time": "2023-12-26T19:08:29.105858400Z"
    }
   },
   "id": "85630df345ad8dc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This concludes loading the data, now we can generate our RNN and train it!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbae252b7ad053"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Recurrent Neural Network\n",
    "\n",
    "The architecture of the RNN we use consumes a list of notes represented by tuples that gets fed through a convolutional neural network (CNN) block, a gated recurrent unit (GRU) block and then through a linear block with a dropout layer."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca54b209d4d1ef89"
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from PM2S.models.blocks import ConvBlock, GRUBlock, LinearOutput\n",
    "from PM2S.constants import keyVocabSize\n",
    "from PM2S.models.utils import get_in_features, encode_note_sequence\n",
    "\n",
    "\n",
    "class RNNKeySignatureModel(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size=512):\n",
    "        super().__init__()\n",
    "\n",
    "        in_features = get_in_features()\n",
    "\n",
    "        self.convs = ConvBlock(in_features=in_features)\n",
    "\n",
    "        self.gru = GRUBlock(in_features=hidden_size)\n",
    "\n",
    "        self.out = LinearOutput(in_features=hidden_size, out_features=keyVocabSize, activation_type='softmax')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, len(features)==4)\n",
    "        x = encode_note_sequence(x)\n",
    "\n",
    "        x = self.convs(x) # (batch_size, seq_len, hidden_size)\n",
    "        x = self.gru(x) # (batch_size, seq_len, hidden_size)\n",
    "        y = self.out(x) # (batch_size, seq_len, keyVocabSize)\n",
    "        y = y.transpose(1, 2) # (batch_size, keyVocabSize, seq_len)\n",
    "\n",
    "        return y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T19:08:30.131122100Z",
     "start_time": "2023-12-26T19:08:30.098210900Z"
    }
   },
   "id": "d2138fb6b9aa1ff5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Module\n",
    "\n",
    "Before we can start training, we have to wrap our model in a KeySignatureModel that handles training and validation steps by calculating the loss and f1 score."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6452a59d5913044"
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import os, sys\n",
    "\n",
    "from PM2S.modules.utils import configure_callbacks, configure_optimizers, classification_report_framewise\n",
    "\n",
    "sys.path.insert(0, os.path.join(sys.path[0], '..'))\n",
    "import torch.nn as nn\n",
    "\n",
    "class KeySignatureModule(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = RNNKeySignatureModel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return configure_optimizers(self)\n",
    "\n",
    "    def configure_callbacks(self):\n",
    "        return configure_callbacks(monitor='val_f1')\n",
    "\n",
    "    def training_step(self, batch, batch_size):\n",
    "        # Data\n",
    "        x, y, length = batch\n",
    "        x = x.float()\n",
    "        y = y.long()\n",
    "        length = length.long()\n",
    "\n",
    "        # Forward pass\n",
    "        y_hat = self(x)\n",
    "\n",
    "        # Mask out the padding part\n",
    "        mask = torch.ones(y_hat.shape).to(y_hat.device)\n",
    "        for i in range(y_hat.shape[0]):\n",
    "            mask[i, length[i]:] = 0\n",
    "        y_hat = y_hat * mask\n",
    "\n",
    "        # Loss\n",
    "        loss = nn.NLLLoss()(y_hat, y)\n",
    "\n",
    "        # Logging\n",
    "        logs = {\n",
    "            'train_loss': loss,\n",
    "        }\n",
    "        self.log_dict(logs, prog_bar=True)\n",
    "\n",
    "        return {'loss': loss, 'logs': logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_size):\n",
    "        # Data\n",
    "        x, y, length = batch\n",
    "        x = x.float()\n",
    "        y = y.long()\n",
    "        length = length.long()\n",
    "\n",
    "        # Forward pass\n",
    "        y_hat = self(x)\n",
    "\n",
    "        # Mask out the padding part\n",
    "        for i in range(y_hat.shape[0]):\n",
    "            y_hat[i, length[i]:] = 0\n",
    "\n",
    "        # Loss\n",
    "        loss = nn.NLLLoss()(y_hat, y)\n",
    "\n",
    "        # Metrics\n",
    "        f_macro_all = 0\n",
    "\n",
    "        for i in range(y_hat.shape[0]):\n",
    "            # get sample from batch\n",
    "            y_hat_i = y_hat[i, :, :length[i]].topk(1, dim=0)[1][0]\n",
    "            y_i = y[i, :length[i]]\n",
    "\n",
    "            # get accuracies\n",
    "            (\n",
    "                _, _, f_macro,\n",
    "                _, _, _\n",
    "            ) = classification_report_framewise(y_i, y_hat_i)\n",
    "\n",
    "            f_macro_all += f_macro\n",
    "\n",
    "        f_macro_all /= y_hat.shape[0]\n",
    "\n",
    "        # Logging\n",
    "        logs = {\n",
    "            'val_loss': loss,\n",
    "            'val_f1': f_macro_all,\n",
    "        }\n",
    "        self.log_dict(logs, prog_bar=True)\n",
    "\n",
    "        return {'loss': loss, 'logs': logs}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T19:08:30.902391800Z",
     "start_time": "2023-12-26T19:08:30.865490100Z"
    }
   },
   "id": "92efd1c3c770f2fa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "\n",
    "Now, let's put everything together and train the model! If you have the whole dataset at hand, change the path in the code below to its location. Please make sure the first line has no '//' at the start because the column labels will not be processed then, also \"tempo(bpm)\" should be replaced by \"tempo\"."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff0f503660973fae"
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    # Data\n",
    "    data_module = Pm2sDataModule(args, feature=args.feature, full_train=args.full_train)\n",
    "\n",
    "    # Model\n",
    "    if args.feature == 'key_signature':\n",
    "        model = KeySignatureModule()\n",
    "    elif args.feature == 'time_signature':\n",
    "        model = TimeSignatureModule() # will be important later\n",
    "    else:\n",
    "        raise ValueError('Invalid feature type.')\n",
    "\n",
    "    # Trainer\n",
    "    trainer = pl.Trainer(\n",
    "        default_root_dir=os.path.join(args.workspace, 'mlruns'),\n",
    "        log_every_n_steps=50,\n",
    "        reload_dataloaders_every_n_epochs=True\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    trainer.fit(model, data_module)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T19:08:31.672043700Z",
     "start_time": "2023-12-26T19:08:31.643126700Z"
    }
   },
   "id": "377bb7d6bd15ea56"
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                 | Params\n",
      "-----------------------------------------------\n",
      "0 | model | RNNKeySignatureModel | 10.5 M\n",
      "-----------------------------------------------\n",
      "10.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.5 M    Total params\n",
      "42.011    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32bbc4e2b77440718cca1b2ab64b5db4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f91443e342214e85be85fd596c8e6efe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class KeyTrainArgs:\n",
    "    workspace = '.' # set to your workspace which contains the dataset\n",
    "    feature = 'key_signature'\n",
    "    full_train = True\n",
    "\n",
    "train(KeyTrainArgs())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T19:10:04.388266500Z",
     "start_time": "2023-12-26T19:08:32.259763400Z"
    }
   },
   "id": "e55b2d40c49819b0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model saving\n",
    "\n",
    "When the model is trained long enough, checkpoints are created in the 'mlruns' folder. To export these models for predicting the key of unlabelled pieces, we have to process and save them as a .pth file."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "317cffde9c3872e9"
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def save_model(args):\n",
    "    if args.feature == 'time_signature':\n",
    "        module = TimeSignatureModule.load_from_checkpoint(args.model_checkpoint_path) # will be important later\n",
    "        model_save_path = '../_model_state_dicts/time_signature/RNNTimeSignatureModel.pth'\n",
    "\n",
    "    elif args.feature == 'key_signature':\n",
    "        module = KeySignatureModule.load_from_checkpoint(args.model_checkpoint_path)\n",
    "        model_save_path = '../_model_state_dicts/key_signature/RNNKeySignatureModel.pth'\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Invalid feature type.')\n",
    "        \n",
    "    Path.mkdir(Path(model_save_path).parent, parents=True, exist_ok=True)\n",
    "    torch.save(module.model.state_dict(), model_save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T19:11:33.480135Z",
     "start_time": "2023-12-26T19:11:33.447223600Z"
    }
   },
   "id": "3ec0b02da846a967"
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/Documents/Uni/MusicInformatics/Music-Informatics/Challenges/mlruns/lightning_logs/version_#/checkpoints/#.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[98], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m     model_checkpoint_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmlruns\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlightning_logs\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mversion_#\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcheckpoints\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#.ckpt\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;66;03m# insert path your trained model here\u001B[39;00m\n\u001B[0;32m      3\u001B[0m     feature \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkey_signature\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m----> 5\u001B[0m \u001B[43msave_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mKeySaveArgs\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[97], line 12\u001B[0m, in \u001B[0;36msave_model\u001B[1;34m(args)\u001B[0m\n\u001B[0;32m      9\u001B[0m     model_save_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../_model_state_dicts/time_signature/RNNTimeSignatureModel.pth\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m args\u001B[38;5;241m.\u001B[39mfeature \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkey_signature\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m---> 12\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[43mKeySignatureModule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_from_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_checkpoint_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m     model_save_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../_model_state_dicts/key_signature/RNNKeySignatureModel.pth\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pm2s\\lib\\site-packages\\pytorch_lightning\\core\\module.py:1552\u001B[0m, in \u001B[0;36mLightningModule.load_from_checkpoint\u001B[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001B[0m\n\u001B[0;32m   1471\u001B[0m \u001B[38;5;129m@_restricted_classmethod\u001B[39m\n\u001B[0;32m   1472\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_from_checkpoint\u001B[39m(\n\u001B[0;32m   1473\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1478\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m   1479\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Self:\n\u001B[0;32m   1480\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001B[39;00m\n\u001B[0;32m   1481\u001B[0m \u001B[38;5;124;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001B[39;00m\n\u001B[0;32m   1482\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1550\u001B[0m \n\u001B[0;32m   1551\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1552\u001B[0m     loaded \u001B[38;5;241m=\u001B[39m _load_from_checkpoint(\n\u001B[0;32m   1553\u001B[0m         \u001B[38;5;28mcls\u001B[39m,  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m   1554\u001B[0m         checkpoint_path,\n\u001B[0;32m   1555\u001B[0m         map_location,\n\u001B[0;32m   1556\u001B[0m         hparams_file,\n\u001B[0;32m   1557\u001B[0m         strict,\n\u001B[0;32m   1558\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   1559\u001B[0m     )\n\u001B[0;32m   1560\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(Self, loaded)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pm2s\\lib\\site-packages\\pytorch_lightning\\core\\saving.py:61\u001B[0m, in \u001B[0;36m_load_from_checkpoint\u001B[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001B[0m\n\u001B[0;32m     59\u001B[0m map_location \u001B[38;5;241m=\u001B[39m map_location \u001B[38;5;129;01mor\u001B[39;00m _default_map_location\n\u001B[0;32m     60\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m pl_legacy_patch():\n\u001B[1;32m---> 61\u001B[0m     checkpoint \u001B[38;5;241m=\u001B[39m \u001B[43mpl_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmap_location\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;66;03m# convert legacy checkpoints to the new format\u001B[39;00m\n\u001B[0;32m     64\u001B[0m checkpoint \u001B[38;5;241m=\u001B[39m _pl_migrate_checkpoint(\n\u001B[0;32m     65\u001B[0m     checkpoint, checkpoint_path\u001B[38;5;241m=\u001B[39m(checkpoint_path \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(checkpoint_path, (\u001B[38;5;28mstr\u001B[39m, Path)) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     66\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pm2s\\lib\\site-packages\\lightning_fabric\\utilities\\cloud_io.py:54\u001B[0m, in \u001B[0;36m_load\u001B[1;34m(path_or_url, map_location)\u001B[0m\n\u001B[0;32m     49\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mhub\u001B[38;5;241m.\u001B[39mload_state_dict_from_url(\n\u001B[0;32m     50\u001B[0m         \u001B[38;5;28mstr\u001B[39m(path_or_url),\n\u001B[0;32m     51\u001B[0m         map_location\u001B[38;5;241m=\u001B[39mmap_location,  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m     52\u001B[0m     )\n\u001B[0;32m     53\u001B[0m fs \u001B[38;5;241m=\u001B[39m get_filesystem(path_or_url)\n\u001B[1;32m---> 54\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mfs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_or_url\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m     55\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mload(f, map_location\u001B[38;5;241m=\u001B[39mmap_location)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pm2s\\lib\\site-packages\\fsspec\\spec.py:1309\u001B[0m, in \u001B[0;36mAbstractFileSystem.open\u001B[1;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001B[0m\n\u001B[0;32m   1307\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1308\u001B[0m     ac \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mautocommit\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_intrans)\n\u001B[1;32m-> 1309\u001B[0m     f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_open(\n\u001B[0;32m   1310\u001B[0m         path,\n\u001B[0;32m   1311\u001B[0m         mode\u001B[38;5;241m=\u001B[39mmode,\n\u001B[0;32m   1312\u001B[0m         block_size\u001B[38;5;241m=\u001B[39mblock_size,\n\u001B[0;32m   1313\u001B[0m         autocommit\u001B[38;5;241m=\u001B[39mac,\n\u001B[0;32m   1314\u001B[0m         cache_options\u001B[38;5;241m=\u001B[39mcache_options,\n\u001B[0;32m   1315\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   1316\u001B[0m     )\n\u001B[0;32m   1317\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m compression \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1318\u001B[0m         \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mfsspec\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompression\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compr\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pm2s\\lib\\site-packages\\fsspec\\implementations\\local.py:180\u001B[0m, in \u001B[0;36mLocalFileSystem._open\u001B[1;34m(self, path, mode, block_size, **kwargs)\u001B[0m\n\u001B[0;32m    178\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_mkdir \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m    179\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmakedirs(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parent(path), exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m--> 180\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m LocalFileOpener(path, mode, fs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pm2s\\lib\\site-packages\\fsspec\\implementations\\local.py:298\u001B[0m, in \u001B[0;36mLocalFileOpener.__init__\u001B[1;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001B[0m\n\u001B[0;32m    296\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompression \u001B[38;5;241m=\u001B[39m get_compression(path, compression)\n\u001B[0;32m    297\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocksize \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mDEFAULT_BUFFER_SIZE\n\u001B[1;32m--> 298\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pm2s\\lib\\site-packages\\fsspec\\implementations\\local.py:303\u001B[0m, in \u001B[0;36mLocalFileOpener._open\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    301\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf\u001B[38;5;241m.\u001B[39mclosed:\n\u001B[0;32m    302\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mautocommit \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m--> 303\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    304\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompression:\n\u001B[0;32m    305\u001B[0m             compress \u001B[38;5;241m=\u001B[39m compr[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompression]\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'D:/Documents/Uni/MusicInformatics/Music-Informatics/Challenges/mlruns/lightning_logs/version_#/checkpoints/#.ckpt'"
     ]
    }
   ],
   "source": [
    "class KeySaveArgs:\n",
    "    model_checkpoint_path = os.path.join('.', 'mlruns', 'lightning_logs', 'version_#', 'checkpoints', '#.ckpt') # insert path your trained model here\n",
    "    feature = 'key_signature'\n",
    "\n",
    "save_model(KeySaveArgs())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T19:11:40.782353200Z",
     "start_time": "2023-12-26T19:11:40.598184Z"
    }
   },
   "id": "7cc79124e4e5f883"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction\n",
    "\n",
    "The RNN we trained now can be fed data from .midi files to predict when the key of the piece changes. As our performances generally are only in a single key, we have to aggregate these outputs. To do so, we sum up all the durations of the predicted keys by subtracting their start time from the time of the next key change, or the end of the piece. Then, we take the key that has the longest duration in the piece."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca5da1f55fa1cf94"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Processor\n",
    "\n",
    "We create a class that processes a collection of unlabelled inputs. Please download the trained model from out [GitHub](https://github.com/ZekReshi/Music-Informatics) or set the path in the code below to your own model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "775b38aeaf594575"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from PM2S.features._processor import MIDIProcessor\n",
    "from PM2S.constants import keyNumber2Name\n",
    "\n",
    "\n",
    "class RNNKeySignatureProcessor(MIDIProcessor):\n",
    "\n",
    "    def __init__(self, model_state_dict_path='_model_state_dicts/key_signature/RNNKeySignatureModel.pth', **kwargs):\n",
    "        super().__init__(model_state_dict_path, **kwargs)\n",
    "\n",
    "    def load(self, state_dict_path):\n",
    "        if state_dict_path:\n",
    "            self._model = RNNKeySignatureModel()\n",
    "            self._model.load_state_dict(torch.load(state_dict_path))\n",
    "        else:\n",
    "            self._model = RNNKeySignatureModel()\n",
    "\n",
    "    def process(self, note_seq, **kwargs):\n",
    "        x = torch.tensor(note_seq).unsqueeze(0)\n",
    "\n",
    "        # Forward pass\n",
    "        key_probs = self._model(x)\n",
    "\n",
    "        # Post-processing\n",
    "        key_idx = key_probs[0].topk(1, dim=0)[1].squeeze(0).cpu().detach().numpy() # (seq_len,)\n",
    "\n",
    "        onsets = note_seq[:, 1]\n",
    "        key_signature_changes = self.pps(key_idx, onsets)\n",
    "\n",
    "        return key_signature_changes\n",
    "\n",
    "    def pps(self, key_idx, onsets):\n",
    "        ks_prev = '0'\n",
    "        ks_changes = []\n",
    "        for i in range(len(key_idx)):\n",
    "            ks_cur = keyNumber2Name[key_idx[i]]\n",
    "            if i == 0 or ks_cur != ks_prev:\n",
    "                onset_cur = onsets[i]\n",
    "                ks_changes.append((onset_cur, ks_cur))\n",
    "                ks_prev = ks_cur\n",
    "        return ks_changes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T19:12:11.411683400Z",
     "start_time": "2023-12-26T19:12:11.399716500Z"
    }
   },
   "id": "8548ad37d48bcfa8"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8: .\\Dataset\\mi2023_key-meter_train_000.mid\n",
      "Prediction: E\n",
      "2/8: .\\Dataset\\mi2023_key-meter_train_001.mid\n",
      "Prediction: C#m\n",
      "3/8: .\\Dataset\\mi2023_key-meter_train_002.mid\n",
      "Prediction: Dm\n",
      "4/8: .\\Dataset\\mi2023_key-meter_train_003.mid\n",
      "Prediction: G\n",
      "5/8: .\\Dataset\\mi2023_key-meter_train_004.mid\n",
      "Prediction: Em\n",
      "6/8: .\\Dataset\\mi2023_key-meter_train_005.mid\n",
      "Prediction: Em\n",
      "7/8: .\\Dataset\\mi2023_key-meter_train_006.mid\n",
      "Prediction: Dm\n",
      "8/8: .\\Dataset\\mi2023_key-meter_train_007.mid\n",
      "Prediction: F\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class KeyPredictionArgs:\n",
    "    datadir = os.path.join('.', 'Dataset')\n",
    "    modeldir = '.' # insert path to our saved model here\n",
    "    \n",
    "args = KeyPredictionArgs()\n",
    "\n",
    "midi_files = glob.glob(os.path.join(args.datadir, \"*.mid\"))\n",
    "midi_files.sort()\n",
    "\n",
    "# Create time and key processors\n",
    "processor_key_sig = RNNKeySignatureProcessor(os.path.join(args.modeldir, '_model_state_dicts', 'key_signature', 'RNNKeySignatureModel.pth'))\n",
    "\n",
    "results = []\n",
    "# Prediction\n",
    "for idx, file in enumerate(midi_files):\n",
    "    p = pt.load_performance_midi(Path(file))\n",
    "    note_array = p.note_array()\n",
    "    note_sequence = np.array(list(zip(note_array['pitch'], note_array['onset_sec'], note_array['duration_sec'], note_array['velocity'])))\n",
    "\n",
    "    key_signature_changes = processor_key_sig.process(note_sequence)\n",
    "\n",
    "    length = note_sequence[-1][1] + note_sequence[-1][2]\n",
    "\n",
    "    last_onset, last_key = key_signature_changes[0]\n",
    "    durations = {}\n",
    "    for onset, key in key_signature_changes[1:]:\n",
    "        if last_key not in durations.keys():\n",
    "            durations[last_key] = 0\n",
    "        durations[last_key] += onset - last_onset\n",
    "        last_onset = onset\n",
    "        last_key = key\n",
    "    if last_key not in durations.keys():\n",
    "        durations[last_key] = 0\n",
    "    durations[last_key] += length - last_onset\n",
    "\n",
    "    best_duration, best_key = 0, 0\n",
    "    for key, duration in durations.items():\n",
    "        if duration > best_duration:\n",
    "            best_duration = duration\n",
    "            best_key = key\n",
    "\n",
    "    print(f\"{str(idx + 1)}/{str(len(midi_files))}: {file}\")\n",
    "    print(\"Prediction: \" + str(best_key))\n",
    "\n",
    "    results.append((os.path.basename(file), best_key))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T19:14:01.976141300Z",
     "start_time": "2023-12-26T19:13:53.163208800Z"
    }
   },
   "id": "60f1f5c283fce51"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "This model, when applied to our data, is able to solve this challenge in a satisfying manner as our team is placed number 1 on the leaderboard (as of December 26th). After a couple of hours of training (about 13 epochs), we already achieved an f-score of 0.97, but this score must be taken with a grain of salt as the verification is done with pieces from the training set. We reached an average tonal distance of 0.379, which tells us that our model is right most of the time, and if it does not output the right key it is probably not that far off, i.e. a C major key is wrongly detected as an A minor key, which uses the same notes but has a different root."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca316e65ae461da7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Meter estimation challenge\n",
    "\n",
    "Very similarly to the key estimation challenge, the meter estimation challenge is about processing performed pieces to calculate which meter the piece is written in, e.g. 4/4 or 3/4. But this challenge only takes the numerator into account because the challenge already is quite hard. The provided dataset is the same as the dataset for the key estimation challenge, and our solution also uses many components that have been seen in the above paragraphs. Therefore, it is required to execute the code above for this part to work. \n",
    "\n",
    "At first, we will only look at the meter, not the tempo."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "986710b7b828b5d5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset\n",
    "\n",
    "This part is nearly a carbon copy of the one above, so we will just create the classes without further elaboration."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ccf7c5e30a7fd50"
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "class TimeSignatureDataset(BaseDataset):\n",
    "\n",
    "    def __init__(self, workspace, split):\n",
    "        super().__init__(workspace, split)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        row = self._sample_row(idx)\n",
    "        note_sequence, annotations = self._load_data(row)\n",
    "\n",
    "        # Get model output data\n",
    "        time_signatures = annotations['time_signatures']\n",
    "        ts_numerators = np.zeros(len(note_sequence)).astype(float)\n",
    "\n",
    "        for i in range(len(note_sequence)):\n",
    "            onset = note_sequence[i, 1]\n",
    "            for ts in time_signatures:\n",
    "                if ts[0] > onset + tolerance:\n",
    "                    break\n",
    "                ts_numerators[i] = tsNume2Index[int(ts[1])] if int(ts[1]) in tsNume2Index.keys() else 0\n",
    "\n",
    "        # padding\n",
    "        length = len(note_sequence)\n",
    "        if length < max_length:\n",
    "            note_sequence = np.concatenate([note_sequence, np.zeros((max_length - length, 4))])\n",
    "            ts_numerators = np.concatenate([ts_numerators, np.zeros(max_length - length)])\n",
    "\n",
    "        return note_sequence, ts_numerators, length"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T19:22:41.798769Z",
     "start_time": "2023-12-26T19:22:41.727958700Z"
    }
   },
   "id": "61d72ca5e55f52aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Recurrent Neural Network\n",
    "\n",
    "The RNN model as well as the module wrapper is also the same as for the key estimation challenge, the only difference being the last layer, which of course has to provide different (less) classes as an output."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c909756b92cd0bf3"
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "class RNNTimeSignatureModel(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size=512):\n",
    "        super().__init__()\n",
    "\n",
    "        in_features = get_in_features()\n",
    "\n",
    "        self.convs = ConvBlock(in_features=in_features)\n",
    "        self.gru = GRUBlock(in_features=hidden_size)\n",
    "        self.out_tn = LinearOutput(in_features=hidden_size, out_features=tsNumeVocabSize, activation_type='softmax')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, len(features)==4)\n",
    "        x = encode_note_sequence(x)\n",
    "\n",
    "        x = self.convs(x)  # (batch_size, seq_len, hidden_size)\n",
    "\n",
    "        x_gru = self.gru(x)  # (batch_size, seq_len, hidden_size)\n",
    "        y_tn = self.out_tn(x_gru)  # (batch_size, seq_len, tsNumeVocabSize)\n",
    "        y_tn = y_tn.permute(0, 2, 1)  # (batch_size, tsNumeVocabSize, seq_len)\n",
    "\n",
    "        return y_tn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T19:25:18.699272800Z",
     "start_time": "2023-12-26T19:25:18.684282200Z"
    }
   },
   "id": "70f6c0e5d25e95f4"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "class TimeSignatureModule(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = RNNTimeSignatureModel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return configure_optimizers(self)\n",
    "\n",
    "    def configure_callbacks(self):\n",
    "        return configure_callbacks(monitor='val_f1')\n",
    "\n",
    "    def training_step(self, batch, batch_size):\n",
    "        # Data\n",
    "        x, y_tn, length = batch\n",
    "        x = x.float()\n",
    "        y_tn = y_tn.long()\n",
    "        length = length.long()\n",
    "\n",
    "        # Forward pass\n",
    "        y_tn_hat = self(x)\n",
    "\n",
    "        # Mask out the padding part\n",
    "        pad_mask = torch.ones((y_tn_hat.shape[0], y_tn_hat.shape[2])).to(y_tn_hat.device)\n",
    "        for i in range(y_tn_hat.shape[0]):\n",
    "            pad_mask[i, length[i]:] = 0\n",
    "        y_tn_hat = y_tn_hat * pad_mask.unsqueeze(1)\n",
    "\n",
    "        # Loss\n",
    "        loss = nn.NLLLoss(ignore_index=0)(y_tn_hat, y_tn)\n",
    "\n",
    "        # Logging\n",
    "        logs = {\n",
    "            'train_loss': loss,\n",
    "        }\n",
    "        self.log_dict(logs, prog_bar=True)\n",
    "\n",
    "        return {'loss': loss, 'logs': logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_size):\n",
    "        # Data\n",
    "        x, y_tn, length = batch\n",
    "        x = x.float()\n",
    "        y_tn = y_tn.long()\n",
    "        length = length.long()\n",
    "\n",
    "        # Forward pass\n",
    "        y_tn_hat = self(x)\n",
    "\n",
    "        # Mask out the padding part\n",
    "        for i in range(y_tn_hat.shape[0]):\n",
    "            y_tn_hat[i, :, length[i]:] = 0\n",
    "\n",
    "        # Loss\n",
    "        loss = nn.NLLLoss(ignore_index=0)(y_tn_hat, y_tn)\n",
    "\n",
    "        # Metrics\n",
    "        fs_macro_tn = 0\n",
    "\n",
    "        for i in range(x.shape[0]):\n",
    "            # get sample from batch\n",
    "            y_tn_hat_i = y_tn_hat[i, :, :length[i]].topk(1, dim=0)[1][0]\n",
    "            y_tn_i = y_tn[i, :length[i]]\n",
    "\n",
    "            # filter out ignored indexes (the same as padding)\n",
    "            y_tn_hat_i = y_tn_hat_i[y_tn_i != 0]\n",
    "            y_tn_i = y_tn_i[y_tn_i != 0]\n",
    "\n",
    "            # get accuracies\n",
    "            (\n",
    "                _, _, f_macro_tn,\n",
    "                _, _, _\n",
    "            ) = classification_report_framewise(y_tn_i, y_tn_hat_i)\n",
    "\n",
    "            fs_macro_tn += f_macro_tn\n",
    "\n",
    "        fs_macro_tn /= x.shape[0]\n",
    "\n",
    "        # Logging\n",
    "        logs = {\n",
    "            'val_loss': loss,\n",
    "            'val_f1': fs_macro_tn,\n",
    "        }\n",
    "        self.log_dict(logs, prog_bar=True)\n",
    "\n",
    "        return {'loss': loss, 'logs': logs}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T19:25:19.274538900Z",
     "start_time": "2023-12-26T19:25:19.204693800Z"
    }
   },
   "id": "4661321241b1fa9c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "\n",
    "Now, let's train the model!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8c6bd22f39546c9"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                  | Params\n",
      "------------------------------------------------\n",
      "0 | model | RNNTimeSignatureModel | 10.5 M\n",
      "------------------------------------------------\n",
      "10.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.5 M    Total params\n",
      "41.976    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f379eb0967a0451b8d5095de910567c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b13a34550084f8cb25cad68f6dcb632"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MeterTrainArgs:\n",
    "    workspace = '.' # set to your workspace which contains the dataset\n",
    "    feature = 'time_signature'\n",
    "    full_train = True\n",
    "\n",
    "train(MeterTrainArgs())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T19:26:55.244904300Z",
     "start_time": "2023-12-26T19:26:20.950493Z"
    }
   },
   "id": "2dacf1ad364452a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model saving\n",
    "Now, let's save the model again."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc96b911c66fb5a0"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/Documents/Uni/MusicInformatics/Music-Informatics/Challenges/mlruns/lightning_logs/version_#/checkpoints/#.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[109], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m     model_checkpoint_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmlruns\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlightning_logs\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mversion_#\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcheckpoints\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#.ckpt\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;66;03m# insert path your trained model here\u001B[39;00m\n\u001B[0;32m      3\u001B[0m     feature \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime_signature\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m----> 5\u001B[0m \u001B[43msave_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mMeterSaveArgs\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[97], line 8\u001B[0m, in \u001B[0;36msave_model\u001B[1;34m(args)\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msave_model\u001B[39m(args):\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m args\u001B[38;5;241m.\u001B[39mfeature \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime_signature\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m----> 8\u001B[0m         module \u001B[38;5;241m=\u001B[39m \u001B[43mTimeSignatureModule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_from_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_checkpoint_path\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# will be important later\u001B[39;00m\n\u001B[0;32m      9\u001B[0m         model_save_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../_model_state_dicts/time_signature/RNNTimeSignatureModel.pth\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m args\u001B[38;5;241m.\u001B[39mfeature \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkey_signature\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pm2s\\lib\\site-packages\\pytorch_lightning\\core\\module.py:1552\u001B[0m, in \u001B[0;36mLightningModule.load_from_checkpoint\u001B[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001B[0m\n\u001B[0;32m   1471\u001B[0m \u001B[38;5;129m@_restricted_classmethod\u001B[39m\n\u001B[0;32m   1472\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_from_checkpoint\u001B[39m(\n\u001B[0;32m   1473\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1478\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m   1479\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Self:\n\u001B[0;32m   1480\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001B[39;00m\n\u001B[0;32m   1481\u001B[0m \u001B[38;5;124;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001B[39;00m\n\u001B[0;32m   1482\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1550\u001B[0m \n\u001B[0;32m   1551\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1552\u001B[0m     loaded \u001B[38;5;241m=\u001B[39m _load_from_checkpoint(\n\u001B[0;32m   1553\u001B[0m         \u001B[38;5;28mcls\u001B[39m,  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m   1554\u001B[0m         checkpoint_path,\n\u001B[0;32m   1555\u001B[0m         map_location,\n\u001B[0;32m   1556\u001B[0m         hparams_file,\n\u001B[0;32m   1557\u001B[0m         strict,\n\u001B[0;32m   1558\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   1559\u001B[0m     )\n\u001B[0;32m   1560\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(Self, loaded)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pm2s\\lib\\site-packages\\pytorch_lightning\\core\\saving.py:61\u001B[0m, in \u001B[0;36m_load_from_checkpoint\u001B[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001B[0m\n\u001B[0;32m     59\u001B[0m map_location \u001B[38;5;241m=\u001B[39m map_location \u001B[38;5;129;01mor\u001B[39;00m _default_map_location\n\u001B[0;32m     60\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m pl_legacy_patch():\n\u001B[1;32m---> 61\u001B[0m     checkpoint \u001B[38;5;241m=\u001B[39m \u001B[43mpl_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmap_location\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;66;03m# convert legacy checkpoints to the new format\u001B[39;00m\n\u001B[0;32m     64\u001B[0m checkpoint \u001B[38;5;241m=\u001B[39m _pl_migrate_checkpoint(\n\u001B[0;32m     65\u001B[0m     checkpoint, checkpoint_path\u001B[38;5;241m=\u001B[39m(checkpoint_path \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(checkpoint_path, (\u001B[38;5;28mstr\u001B[39m, Path)) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     66\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pm2s\\lib\\site-packages\\lightning_fabric\\utilities\\cloud_io.py:54\u001B[0m, in \u001B[0;36m_load\u001B[1;34m(path_or_url, map_location)\u001B[0m\n\u001B[0;32m     49\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mhub\u001B[38;5;241m.\u001B[39mload_state_dict_from_url(\n\u001B[0;32m     50\u001B[0m         \u001B[38;5;28mstr\u001B[39m(path_or_url),\n\u001B[0;32m     51\u001B[0m         map_location\u001B[38;5;241m=\u001B[39mmap_location,  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m     52\u001B[0m     )\n\u001B[0;32m     53\u001B[0m fs \u001B[38;5;241m=\u001B[39m get_filesystem(path_or_url)\n\u001B[1;32m---> 54\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mfs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_or_url\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m     55\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mload(f, map_location\u001B[38;5;241m=\u001B[39mmap_location)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pm2s\\lib\\site-packages\\fsspec\\spec.py:1309\u001B[0m, in \u001B[0;36mAbstractFileSystem.open\u001B[1;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001B[0m\n\u001B[0;32m   1307\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1308\u001B[0m     ac \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mautocommit\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_intrans)\n\u001B[1;32m-> 1309\u001B[0m     f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_open(\n\u001B[0;32m   1310\u001B[0m         path,\n\u001B[0;32m   1311\u001B[0m         mode\u001B[38;5;241m=\u001B[39mmode,\n\u001B[0;32m   1312\u001B[0m         block_size\u001B[38;5;241m=\u001B[39mblock_size,\n\u001B[0;32m   1313\u001B[0m         autocommit\u001B[38;5;241m=\u001B[39mac,\n\u001B[0;32m   1314\u001B[0m         cache_options\u001B[38;5;241m=\u001B[39mcache_options,\n\u001B[0;32m   1315\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   1316\u001B[0m     )\n\u001B[0;32m   1317\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m compression \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1318\u001B[0m         \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mfsspec\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompression\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compr\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pm2s\\lib\\site-packages\\fsspec\\implementations\\local.py:180\u001B[0m, in \u001B[0;36mLocalFileSystem._open\u001B[1;34m(self, path, mode, block_size, **kwargs)\u001B[0m\n\u001B[0;32m    178\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_mkdir \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m    179\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmakedirs(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parent(path), exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m--> 180\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m LocalFileOpener(path, mode, fs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pm2s\\lib\\site-packages\\fsspec\\implementations\\local.py:298\u001B[0m, in \u001B[0;36mLocalFileOpener.__init__\u001B[1;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001B[0m\n\u001B[0;32m    296\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompression \u001B[38;5;241m=\u001B[39m get_compression(path, compression)\n\u001B[0;32m    297\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocksize \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mDEFAULT_BUFFER_SIZE\n\u001B[1;32m--> 298\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pm2s\\lib\\site-packages\\fsspec\\implementations\\local.py:303\u001B[0m, in \u001B[0;36mLocalFileOpener._open\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    301\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf\u001B[38;5;241m.\u001B[39mclosed:\n\u001B[0;32m    302\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mautocommit \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m--> 303\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    304\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompression:\n\u001B[0;32m    305\u001B[0m             compress \u001B[38;5;241m=\u001B[39m compr[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompression]\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'D:/Documents/Uni/MusicInformatics/Music-Informatics/Challenges/mlruns/lightning_logs/version_#/checkpoints/#.ckpt'"
     ]
    }
   ],
   "source": [
    "class MeterSaveArgs:\n",
    "    model_checkpoint_path = os.path.join('.', 'mlruns', 'lightning_logs', 'version_#', 'checkpoints', '#.ckpt') # insert path your trained model here\n",
    "    feature = 'time_signature'\n",
    "\n",
    "save_model(MeterSaveArgs())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T19:27:45.973298600Z",
     "start_time": "2023-12-26T19:27:45.640353300Z"
    }
   },
   "id": "cc86980f8e5bd585"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction\n",
    "Yet again, we employ the same technique as we did when solving the key estimation challenge. The RNN outputs a list of time signature changes, and we aggregate them to find the time signature that is predicted for the longest duration."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8ced3253a09191c"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "class RNNTimeSignatureProcessor(MIDIProcessor):\n",
    "\n",
    "    def __init__(self, model_state_dict_path='_model_state_dicts/time_signature/RNNTimeSignatureModel.pth', **kwargs):\n",
    "        super().__init__(model_state_dict_path, **kwargs)\n",
    "\n",
    "    def load(self, state_dict_path):\n",
    "        if state_dict_path:\n",
    "            self._model = RNNTimeSignatureModel()\n",
    "            self._model.load_state_dict(torch.load(state_dict_path))\n",
    "        else:\n",
    "            self._model = RNNTimeSignatureModel()\n",
    "\n",
    "    def process(self, note_seq, **kwargs):\n",
    "        x = torch.tensor(note_seq).unsqueeze(0)\n",
    "\n",
    "        # Forward pass\n",
    "        tn_probs = self._model(x)\n",
    "\n",
    "        # Post-processing\n",
    "        tn_idx = tn_probs[0].topk(1, dim=0)[1].squeeze(0).cpu().detach().numpy() # (seq_len,)\n",
    "\n",
    "        onsets = note_seq[:, 1]\n",
    "        time_signature_changes = self.pps(tn_idx, onsets)\n",
    "\n",
    "        return time_signature_changes\n",
    "\n",
    "    def pps(self, tn_idx, onsets):\n",
    "        ts_prev = '0/0'\n",
    "        ts_changes = []\n",
    "        for i in range(len(tn_idx)):\n",
    "            ts_cur = '{:d}'.format(tsIndex2Nume[tn_idx[i]])\n",
    "            if i == 0 or ts_cur != ts_prev:\n",
    "                onset_cur = onsets[i]\n",
    "                ts_changes.append((onset_cur, ts_cur))\n",
    "                ts_prev = ts_cur\n",
    "        return ts_changes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T19:29:30.213112Z",
     "start_time": "2023-12-26T19:29:30.143253400Z"
    }
   },
   "id": "d0672c37b2e760d0"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8: .\\Dataset\\mi2023_key-meter_train_000.mid\n",
      "Prediction: 12\n",
      "2/8: .\\Dataset\\mi2023_key-meter_train_001.mid\n",
      "Prediction: 6\n",
      "3/8: .\\Dataset\\mi2023_key-meter_train_002.mid\n",
      "Prediction: 4\n",
      "4/8: .\\Dataset\\mi2023_key-meter_train_003.mid\n",
      "Prediction: 6\n",
      "5/8: .\\Dataset\\mi2023_key-meter_train_004.mid\n",
      "Prediction: 3\n",
      "6/8: .\\Dataset\\mi2023_key-meter_train_005.mid\n",
      "Prediction: 3\n",
      "7/8: .\\Dataset\\mi2023_key-meter_train_006.mid\n",
      "Prediction: 4\n",
      "8/8: .\\Dataset\\mi2023_key-meter_train_007.mid\n",
      "Prediction: 6\n"
     ]
    }
   ],
   "source": [
    "class MeterPredictionArgs:\n",
    "    datadir = os.path.join('.', 'Dataset')\n",
    "    modeldir = '.' # insert path to our saved model here\n",
    "    \n",
    "args = MeterPredictionArgs()\n",
    "\n",
    "midi_files = glob.glob(os.path.join(args.datadir, \"*.mid\"))\n",
    "midi_files.sort()\n",
    "\n",
    "# Create time and key processors\n",
    "processor_time_sig = RNNTimeSignatureProcessor(os.path.join(args.modeldir, '_model_state_dicts', 'time_signature', 'RNNTimeSignatureModel.pth'))\n",
    "\n",
    "# Prediction\n",
    "for idx, file in enumerate(midi_files):\n",
    "    p = pt.load_performance_midi(Path(file))\n",
    "    note_array = p.note_array()\n",
    "    note_sequence = np.array(list(zip(note_array['pitch'], note_array['onset_sec'], note_array['duration_sec'], note_array['velocity'])))\n",
    "\n",
    "    time_signature_changes = processor_time_sig.process(note_sequence)\n",
    "\n",
    "    length = note_sequence[-1][1] + note_sequence[-1][2]\n",
    "\n",
    "    last_onset, last_ts_num = time_signature_changes[0]\n",
    "    durations = {}\n",
    "    for onset, ts_num in time_signature_changes[1:]:\n",
    "        if last_ts_num not in durations.keys():\n",
    "            durations[last_ts_num] = 0\n",
    "        durations[last_ts_num] += onset - last_onset\n",
    "        last_onset = onset\n",
    "        last_ts_num = ts_num\n",
    "    if last_ts_num not in durations.keys():\n",
    "        durations[last_ts_num] = 0\n",
    "    durations[last_ts_num] += length - last_onset\n",
    "\n",
    "    best_duration, best_ts_num = 0, 0\n",
    "    for ts_num, duration in durations.items():\n",
    "        if duration > best_duration:\n",
    "            best_duration = duration\n",
    "            best_ts_num = ts_num\n",
    "\n",
    "    print(f\"{str(idx + 1)}/{str(len(midi_files))}: {file}\")\n",
    "    print(\"Prediction: \" + str(best_ts_num))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T19:31:08.341481800Z",
     "start_time": "2023-12-26T19:30:58.309272900Z"
    }
   },
   "id": "64daa6c5bb647d32"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion of meter estimation\n",
    "\n",
    "With this model, we were able to achieve an f-score of about 0.47, but again this was done on some pieces of the training set. This might not seem like much, but when we applied it so the test set, we reached a score of 0.572, just shy of the current best on the leaderboard (0.575 as of December 26th).\n",
    "\n",
    "Now, we have to take a look at the tempo estimation!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7c44f5232f077d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9d2d1e7a2ca94b31"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
