{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Key estimation challenge\n",
    "\n",
    "This challenge was about finding out which key a piece was written in. The input was a set of .midi files containing performed pieces, and the output was a file that assigned each piece a key.\n",
    "\n",
    "To solve this problem, a recurrent neural network (RNN) was used as described by Liu et al. in [\"PERFORMANCE MIDI-TO-SCORE CONVERSION BY\n",
    "NEURAL BEAT TRACKING\"](https://www.turing.ac.uk/sites/default/files/2022-09/midi_quantisation_paper_ismir_2022_0.pdf). This paper is also explained in a [YouTube-Video](https://www.youtube.com/watch?v=yumxXCYSgbY) and their code is openly available at [GitHub](https://github.com/cheriell/PM2S).\n",
    "The architecture of the paper's neural networks is shown below.\n",
    "For our purposes, the branches ending with key signature and time signature numerators were implemented, but with more classes to support all 24 keys and 2 more numerators (9 and 12).\n",
    "As the original project was about midi performance to score conversion, it was not needed to find out the root of a scale, only the scale itself, e.g. they did not know whether a pieces' scale was C or Am when the notes C, D, E, F, G, H, A, B are in the scale.\n",
    "\n",
    "![Architecture of the paper's neural networks.](img/NN.png)\n",
    "\n",
    "We altered their code base to work with the data set given to us and to produce output in the correct format.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9c6872a2e122ee9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Data\n",
    "\n",
    "At first, we have to load in our data in the format that is accepted by the RNN. Every piece should be transformed into a list of notes represented of a tuple (pitch, onset_sec, duration_sec, velocity). As the RNN is able to handle key signature changes, the label is not a single key, but a list of key signature changes. In our case there is always just one key signature change at the beginning of the piece."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7623616d29d11353"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Augmentation\n",
    "\n",
    "Before we create the data set class, we have to take a look at data augmentation.\n",
    "\n",
    "An easy way to upscale the size of the given data set to prevent overfitting is augmenting the data. In this case, the tempo of the piece can be changed by scaling the onset and duration of every note by a given factor. Even more importantly, the piece can be transposed by changing the pitch of all notes simultaneously. When doing this, the key label also has to be changed, because a piece in B major that is transposed by a semitone upwards is now in C major. Please note that in the original code, there was an error that caused keys to be shifted incorrectly, causing the label of a piece in B major to be set to C minor instead of C major when pitching up by a semitone."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "436509bddd2d1a53"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class DataAugmentation:\n",
    "    def __init__(self,\n",
    "                 tempo_change_prob=1.0,\n",
    "                 tempo_change_range=(0.8, 1.2),\n",
    "                 pitch_shift_prob=1.0,\n",
    "                 pitch_shift_range=(-6, 6)):\n",
    "\n",
    "        self.tempo_change_prob = tempo_change_prob\n",
    "        self.tempo_change_range = tempo_change_range\n",
    "        self.pitch_shift_prob = pitch_shift_prob\n",
    "        self.pitch_shift_range = pitch_shift_range\n",
    "\n",
    "    def __call__(self, note_sequence, annotations):\n",
    "        # tempo change\n",
    "        if random.random() < self.tempo_change_prob:\n",
    "            note_sequence, annotations = self.tempo_change(note_sequence, annotations)\n",
    "\n",
    "        # pitch shift\n",
    "        if random.random() < self.pitch_shift_prob:\n",
    "            note_sequence, annotations = self.pitch_shift(note_sequence, annotations)\n",
    "\n",
    "        return note_sequence, annotations\n",
    "\n",
    "    def tempo_change(self, note_sequence, annotations):\n",
    "        tempo_change_ratio = random.uniform(*self.tempo_change_range)\n",
    "        note_sequence[:, 1:3] *= 1 / tempo_change_ratio\n",
    "        annotations['time_signatures'][:, 0] *= 1 / tempo_change_ratio\n",
    "        annotations['key_signatures'][:, 0] *= 1 / tempo_change_ratio\n",
    "        return note_sequence, annotations\n",
    "\n",
    "    def pitch_shift(self, note_sequence, annotations):\n",
    "        shift = round(random.uniform(*self.pitch_shift_range))\n",
    "        note_sequence[:, 0] += shift\n",
    "\n",
    "        for i in range(len(annotations['key_signatures'])):\n",
    "            key = annotations['key_signatures'][i, 1]\n",
    "            minor_offset = 12 * (key // 12)\n",
    "            scale_offset = key - minor_offset\n",
    "\n",
    "            annotations['key_signatures'][i, 1] = minor_offset + (scale_offset + shift) % 12\n",
    "\n",
    "        return note_sequence, annotations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:07:46.530564500Z",
     "start_time": "2024-01-08T13:07:46.507624700Z"
    }
   },
   "id": "2de1ecd0a77543f8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Base Data Set\n",
    "\n",
    "As we use the same RNN for the key and meter estimation challenges, we have an abstract BaseDataSet for both of them. This data set holds the data and can then generate random batches to feed to the RNN for training."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddbc5141ea2f327c"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.insert(0, os.path.join(sys.path[0], '..'))\n",
    "import torch\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import partitura as pt\n",
    "from pathlib import Path\n",
    "\n",
    "class BaseDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, workspace, split):\n",
    "\n",
    "        # parameters\n",
    "        self.workspace = workspace\n",
    "        self.feature_folder = workspace\n",
    "        self.split = split\n",
    "\n",
    "        # Get metadata by split\n",
    "        self.metadata = pd.read_csv(os.path.join(self.feature_folder, 'key-meter_train_gt.txt'), delimiter=',')\n",
    "        self.metadata.reset_index(inplace=True)\n",
    "\n",
    "        # Get distinct pieces\n",
    "        self.piece2row = defaultdict(list)\n",
    "        for i, row in self.metadata.iterrows():\n",
    "            self.piece2row[row['filename']].append(i)\n",
    "        self.pieces = list(self.piece2row.keys())\n",
    "\n",
    "        # Initialise data augmentation\n",
    "        self.dataaug = DataAugmentation()\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.split == 'train' or self.split == 'all':\n",
    "            # constantly update 200 steps per epoch, not related to training dataset size\n",
    "            # THIS WAS LOWERED TO REDUCE TRAINING TIME IN THIS NOTEBOOK\n",
    "            return batch_size * 20\n",
    "\n",
    "        elif self.split == 'valid':\n",
    "            # by istinct pieces in validation set\n",
    "            # THIS WAS LOWERED TO REDUCE VALIDATION TIME IN THIS NOTEBOOK\n",
    "            return batch_size * 5 #len(self.piece2row) // 10  # valid dataset size\n",
    "\n",
    "        elif self.split == 'test':\n",
    "            return len(self.metadata)\n",
    "\n",
    "    def _sample_row(self, idx):\n",
    "        # Sample one row from the metadata\n",
    "        if self.split == 'train' or self.split == 'all':\n",
    "            piece_id = random.choice(list(self.piece2row.keys()))   # random sampling by piece\n",
    "            row_id = random.choice(self.piece2row[piece_id])\n",
    "        elif self.split == 'valid':\n",
    "            piece_id = self.pieces[idx // batch_size]    # by istinct pieces in validation set\n",
    "            row_id = self.piece2row[piece_id][idx % batch_size % len(self.piece2row[piece_id])]\n",
    "        elif self.split == 'test':\n",
    "            row_id = idx\n",
    "        row = self.metadata.iloc[row_id]\n",
    "\n",
    "        return row\n",
    "\n",
    "    def _load_data(self, row):\n",
    "        # Get feature\n",
    "        p = pt.load_performance_midi(str(Path(self.feature_folder, row['filename'])))\n",
    "        note_array = p.note_array()\n",
    "        note_sequence = np.array(list(zip(note_array['pitch'], note_array['onset_sec'], note_array['duration_sec'], note_array['velocity'])))\n",
    "        annotations = {\n",
    "            'time_signatures': np.array([(0., row['ts_num'])]),\n",
    "            'key_signatures': np.array([(0., keyName2Number[row['key']])]),\n",
    "            'tempo': np.array([(0., row['tempo'])])\n",
    "        }\n",
    "\n",
    "        # Data augmentation\n",
    "        if self.split == 'train' or self.split == 'all':\n",
    "            note_sequence, annotations = self.dataaug(note_sequence, annotations)\n",
    "\n",
    "        # Randomly sample a segment that is at most max_length long\n",
    "        if self.split == 'train' or self.split == 'all':\n",
    "            start_idx = random.randint(0, len(note_sequence)-1)\n",
    "            end_idx = start_idx + max_length\n",
    "        elif self.split == 'valid':\n",
    "            start_idx, end_idx = 0, max_length  # validate on the segment starting with the first note\n",
    "        elif self.split == 'test':\n",
    "            start_idx, end_idx = 0, len(note_sequence)  # test on the whole note sequence\n",
    "\n",
    "        if end_idx > len(note_sequence):\n",
    "            end_idx = len(note_sequence)\n",
    "\n",
    "        note_sequence = note_sequence[start_idx:end_idx]\n",
    "\n",
    "        return note_sequence, annotations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:14:24.565219700Z",
     "start_time": "2024-01-08T13:14:24.459901600Z"
    }
   },
   "id": "3fcddc7e7db9e2f5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Key Signature Data Set\n",
    "\n",
    "To provide key estimation specific data, the abstract BaseDataSet is derived to return the correct label for every item in the dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2c8e33ee096ad8d"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from PM2S.constants import *\n",
    "\n",
    "\n",
    "class KeySignatureDataset(BaseDataset):\n",
    "\n",
    "    def __init__(self, workspace, split):\n",
    "        super().__init__(workspace, split)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        row = self._sample_row(idx)\n",
    "        note_sequence, annotations = self._load_data(row)\n",
    "\n",
    "        # Get model output data\n",
    "        key_signatures = annotations['key_signatures']\n",
    "\n",
    "        key_numbers = np.zeros(len(note_sequence)).astype(float)\n",
    "\n",
    "        for i in range(len(note_sequence)):\n",
    "            onset = note_sequence[i,1]\n",
    "            for ks in key_signatures:\n",
    "                if ks[0] > onset + tolerance:\n",
    "                    break\n",
    "                key_numbers[i] = ks[1] % keyVocabSize\n",
    "\n",
    "        # padding\n",
    "        length = len(note_sequence)\n",
    "        if length < max_length:\n",
    "            note_sequence = np.concatenate([note_sequence, np.zeros((max_length - length, 4))])\n",
    "            key_numbers = np.concatenate([key_numbers, np.zeros(max_length - length)])\n",
    "\n",
    "        return note_sequence, key_numbers, length"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:14:25.217903400Z",
     "start_time": "2024-01-08T13:14:25.200962400Z"
    }
   },
   "id": "5fadc9217034dd3a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data module\n",
    "Pytorch Lightning uses an implementation of a LightningDataModule for the training. It is needed for loading data differently during training, evaluating and testing."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c10e980cd41c414"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from PM2S.configs import *\n",
    "\n",
    "class Pm2sDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, args, feature='key_signature', full_train=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Parameters from input arguments\n",
    "        self.workspace = args.workspace\n",
    "        self.feature = feature\n",
    "        self.full_train = full_train\n",
    "\n",
    "    def _get_dataset(self, split):\n",
    "        if self.feature == 'key_signature':\n",
    "            dataset = KeySignatureDataset(self.workspace, split)\n",
    "        elif self.feature == 'time_signature':\n",
    "            dataset = TimeSignatureDataset(self.workspace, split) # will be important later\n",
    "        else:\n",
    "            raise ValueError('Unknown feature: {}'.format(self.feature))\n",
    "        return dataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        if self.full_train:\n",
    "            dataset = self._get_dataset(split='all')\n",
    "        else:\n",
    "            dataset = self._get_dataset(split='train')\n",
    "        sampler = torch.utils.data.sampler.RandomSampler(dataset)\n",
    "        dataloader = torch.utils.data.dataloader.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            sampler=sampler,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=True\n",
    "        )\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = self._get_dataset(split='valid')\n",
    "        sampler = torch.utils.data.sampler.SequentialSampler(dataset)\n",
    "        dataloader = torch.utils.data.dataloader.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            sampler=sampler,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=True\n",
    "        )\n",
    "        return dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataset = self._get_dataset(split='test')\n",
    "        sampler = torch.utils.data.sampler.SequentialSampler(dataset)\n",
    "        dataloader = torch.utils.data.dataloader.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=1,\n",
    "            sampler=sampler,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=False\n",
    "        )\n",
    "        return dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:14:25.734104800Z",
     "start_time": "2024-01-08T13:14:25.706239400Z"
    }
   },
   "id": "85630df345ad8dc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This concludes loading the data, now we can generate our RNN and train it!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbae252b7ad053"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Recurrent Neural Network\n",
    "\n",
    "The architecture of the RNN we use consumes a list of notes represented by tuples that gets fed through a convolutional neural network (CNN) block, a gated recurrent unit (GRU) block and then through a linear block with a dropout layer."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca54b209d4d1ef89"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from PM2S.models.blocks import ConvBlock, GRUBlock, LinearOutput\n",
    "from PM2S.constants import keyVocabSize\n",
    "from PM2S.models.utils import get_in_features, encode_note_sequence\n",
    "\n",
    "\n",
    "class RNNKeySignatureModel(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size=512):\n",
    "        super().__init__()\n",
    "\n",
    "        in_features = get_in_features()\n",
    "\n",
    "        self.convs = ConvBlock(in_features=in_features)\n",
    "\n",
    "        self.gru = GRUBlock(in_features=hidden_size)\n",
    "\n",
    "        self.out = LinearOutput(in_features=hidden_size, out_features=keyVocabSize, activation_type='softmax')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, len(features)==4)\n",
    "        x = encode_note_sequence(x)\n",
    "\n",
    "        x = self.convs(x) # (batch_size, seq_len, hidden_size)\n",
    "        x = self.gru(x) # (batch_size, seq_len, hidden_size)\n",
    "        y = self.out(x) # (batch_size, seq_len, keyVocabSize)\n",
    "        y = y.transpose(1, 2) # (batch_size, keyVocabSize, seq_len)\n",
    "\n",
    "        return y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:32:42.693673800Z",
     "start_time": "2024-01-08T13:32:42.656740300Z"
    }
   },
   "id": "d2138fb6b9aa1ff5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Module\n",
    "\n",
    "Before we can start training, we have to wrap our model in a KeySignatureModel that handles training and validation steps by calculating the loss and f1 score."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6452a59d5913044"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import os, sys\n",
    "\n",
    "from PM2S.modules.utils import configure_callbacks, configure_optimizers, classification_report_framewise\n",
    "\n",
    "sys.path.insert(0, os.path.join(sys.path[0], '..'))\n",
    "import torch.nn as nn\n",
    "\n",
    "class KeySignatureModule(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = RNNKeySignatureModel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return configure_optimizers(self)\n",
    "\n",
    "    def configure_callbacks(self):\n",
    "        return configure_callbacks(monitor='val_f1')\n",
    "\n",
    "    def training_step(self, batch, batch_size):\n",
    "        # Data\n",
    "        x, y, length = batch\n",
    "        x = x.float()\n",
    "        y = y.long()\n",
    "        length = length.long()\n",
    "\n",
    "        # Forward pass\n",
    "        y_hat = self(x)\n",
    "\n",
    "        # Mask out the padding part\n",
    "        mask = torch.ones(y_hat.shape).to(y_hat.device)\n",
    "        for i in range(y_hat.shape[0]):\n",
    "            mask[i, length[i]:] = 0\n",
    "        y_hat = y_hat * mask\n",
    "\n",
    "        # Loss\n",
    "        loss = nn.NLLLoss()(y_hat, y)\n",
    "\n",
    "        # Logging\n",
    "        logs = {\n",
    "            'train_loss': loss,\n",
    "        }\n",
    "        self.log_dict(logs, prog_bar=True)\n",
    "\n",
    "        return {'loss': loss, 'logs': logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_size):\n",
    "        # Data\n",
    "        x, y, length = batch\n",
    "        x = x.float()\n",
    "        y = y.long()\n",
    "        length = length.long()\n",
    "\n",
    "        # Forward pass\n",
    "        y_hat = self(x)\n",
    "\n",
    "        # Mask out the padding part\n",
    "        for i in range(y_hat.shape[0]):\n",
    "            y_hat[i, length[i]:] = 0\n",
    "\n",
    "        # Loss\n",
    "        loss = nn.NLLLoss()(y_hat, y)\n",
    "\n",
    "        # Metrics\n",
    "        f_macro_all = 0\n",
    "\n",
    "        for i in range(y_hat.shape[0]):\n",
    "            # get sample from batch\n",
    "            y_hat_i = y_hat[i, :, :length[i]].topk(1, dim=0)[1][0]\n",
    "            y_i = y[i, :length[i]]\n",
    "\n",
    "            # get accuracies\n",
    "            (\n",
    "                _, _, f_macro,\n",
    "                _, _, _\n",
    "            ) = classification_report_framewise(y_i, y_hat_i)\n",
    "\n",
    "            f_macro_all += f_macro\n",
    "\n",
    "        f_macro_all /= y_hat.shape[0]\n",
    "\n",
    "        # Logging\n",
    "        logs = {\n",
    "            'val_loss': loss,\n",
    "            'val_f1': f_macro_all,\n",
    "        }\n",
    "        self.log_dict(logs, prog_bar=True)\n",
    "\n",
    "        return {'loss': loss, 'logs': logs}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:32:43.037330Z",
     "start_time": "2024-01-08T13:32:42.972934800Z"
    }
   },
   "id": "92efd1c3c770f2fa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "\n",
    "Now, let's put everything together and train the model! If you have the whole dataset at hand, change the path in the code below to its location. Please make sure the first line has no '//' at the start because the column labels will not be processed then, also \"tempo(bpm)\" should be replaced by \"tempo\".\n",
    "\n",
    "This training will continue until you stop it."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff0f503660973fae"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def train(args):\n",
    "    # Data\n",
    "    data_module = Pm2sDataModule(args, feature=args.feature, full_train=args.full_train)\n",
    "\n",
    "    # Model\n",
    "    if args.feature == 'key_signature':\n",
    "        model = KeySignatureModule()\n",
    "    elif args.feature == 'time_signature':\n",
    "        model = TimeSignatureModule() # will be important later\n",
    "    else:\n",
    "        raise ValueError('Invalid feature type.')\n",
    "\n",
    "    # Trainer\n",
    "    trainer = pl.Trainer(\n",
    "        default_root_dir=os.path.join(args.workspace, 'mlruns'),\n",
    "        log_every_n_steps=50,\n",
    "        reload_dataloaders_every_n_epochs=True\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    trainer.fit(model, data_module)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:32:43.627128300Z",
     "start_time": "2024-01-08T13:32:43.601199900Z"
    }
   },
   "id": "377bb7d6bd15ea56"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                 | Params\n",
      "-----------------------------------------------\n",
      "0 | model | RNNKeySignatureModel | 10.5 M\n",
      "-----------------------------------------------\n",
      "10.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.5 M    Total params\n",
      "42.011    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "781af97e953e4c65a5cbfa19ee283bbe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51abc1da03a44fa09f8859a666f10e54"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1181919ec0ce44ab9a46d39781526025"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e5a14f487fc4a91a7b9ec31e2bc0229"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class KeyTrainArgs:\n",
    "    workspace = os.path.join('.', 'train') # set to your workspace which contains the dataset\n",
    "    feature = 'key_signature'\n",
    "    full_train = True\n",
    "\n",
    "train(KeyTrainArgs())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:21:01.506476500Z",
     "start_time": "2024-01-08T13:14:28.663695800Z"
    }
   },
   "id": "e55b2d40c49819b0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model saving\n",
    "\n",
    "When the model is trained long enough, checkpoints are created in the 'mlruns' folder in your workspace (root folder by default). To export these models for predicting the key of unlabelled pieces, we have to process and save them as a .pth file."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "317cffde9c3872e9"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def save_model(args):\n",
    "    if args.feature == 'time_signature':\n",
    "        module = TimeSignatureModule.load_from_checkpoint(args.model_checkpoint_path) # will be important later\n",
    "        model_save_path = './_model_state_dicts/time_signature/RNNTimeSignatureModel.pth'\n",
    "\n",
    "    elif args.feature == 'key_signature':\n",
    "        module = KeySignatureModule.load_from_checkpoint(args.model_checkpoint_path)\n",
    "        model_save_path = './_model_state_dicts/key_signature/RNNKeySignatureModel.pth'\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Invalid feature type.')\n",
    "        \n",
    "    Path.mkdir(Path(model_save_path).parent, parents=True, exist_ok=True)\n",
    "    torch.save(module.model.state_dict(), model_save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:31:29.760258500Z",
     "start_time": "2024-01-08T13:31:29.728342200Z"
    }
   },
   "id": "3ec0b02da846a967"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "class KeySaveArgs:\n",
    "    model_checkpoint_path = os.path.join('.', 'mlruns', 'lightning_logs', 'version_1', 'checkpoints', 'last.ckpt') # insert path your trained model here\n",
    "    feature = 'key_signature'\n",
    "\n",
    "save_model(KeySaveArgs())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:33:23.914918100Z",
     "start_time": "2024-01-08T13:33:22.670296400Z"
    }
   },
   "id": "7cc79124e4e5f883"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction\n",
    "\n",
    "The RNN we trained now can be fed data from .midi files to predict when the key of the piece changes. As our performances generally are only in a single key, we have to aggregate these outputs. To do so, we sum up all the durations of the predicted keys by subtracting their start time from the time of the next key change, or the end of the piece. Then, we take the key that has the longest duration in the piece."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca5da1f55fa1cf94"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Processor\n",
    "\n",
    "We create a class that processes a collection of unlabelled inputs. Please download the trained model from out [GitHub](https://github.com/ZekReshi/Music-Informatics) by downloading the directory \"_model_state_dicts\" or set the path in the code below to your own model directory."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "775b38aeaf594575"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from PM2S.features._processor import MIDIProcessor\n",
    "from PM2S.constants import keyNumber2Name\n",
    "\n",
    "\n",
    "class RNNKeySignatureProcessor(MIDIProcessor):\n",
    "\n",
    "    def __init__(self, model_state_dict_path='_model_state_dicts/key_signature/RNNKeySignatureModel.pth', **kwargs):\n",
    "        super().__init__(model_state_dict_path, **kwargs)\n",
    "\n",
    "    def load(self, state_dict_path):\n",
    "        if state_dict_path:\n",
    "            self._model = RNNKeySignatureModel()\n",
    "            self._model.load_state_dict(torch.load(state_dict_path))\n",
    "        else:\n",
    "            self._model = RNNKeySignatureModel()\n",
    "\n",
    "    def process(self, note_seq, **kwargs):\n",
    "        x = torch.tensor(note_seq).unsqueeze(0)\n",
    "\n",
    "        # Forward pass\n",
    "        key_probs = self._model(x)\n",
    "\n",
    "        # Post-processing\n",
    "        key_idx = key_probs[0].topk(1, dim=0)[1].squeeze(0).cpu().detach().numpy() # (seq_len,)\n",
    "\n",
    "        onsets = note_seq[:, 1]\n",
    "        key_signature_changes = self.pps(key_idx, onsets)\n",
    "\n",
    "        return key_signature_changes\n",
    "\n",
    "    def pps(self, key_idx, onsets):\n",
    "        ks_prev = '0'\n",
    "        ks_changes = []\n",
    "        for i in range(len(key_idx)):\n",
    "            ks_cur = keyNumber2Name[key_idx[i]]\n",
    "            if i == 0 or ks_cur != ks_prev:\n",
    "                onset_cur = onsets[i]\n",
    "                ks_changes.append((onset_cur, ks_cur))\n",
    "                ks_prev = ks_cur\n",
    "        return ks_changes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:33:28.363160500Z",
     "start_time": "2024-01-08T13:33:28.317282200Z"
    }
   },
   "id": "8548ad37d48bcfa8"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/153: .\\test\\mi2023_key-meter_test_000.mid\n",
      "Prediction: Eb\n",
      "2/153: .\\test\\mi2023_key-meter_test_001.mid\n",
      "Prediction: D#m\n",
      "3/153: .\\test\\mi2023_key-meter_test_002.mid\n",
      "Prediction: C#m\n",
      "4/153: .\\test\\mi2023_key-meter_test_003.mid\n",
      "Prediction: Em\n",
      "5/153: .\\test\\mi2023_key-meter_test_004.mid\n",
      "Prediction: Am\n",
      "6/153: .\\test\\mi2023_key-meter_test_005.mid\n",
      "Prediction: F#\n",
      "7/153: .\\test\\mi2023_key-meter_test_006.mid\n",
      "Prediction: Dm\n",
      "8/153: .\\test\\mi2023_key-meter_test_007.mid\n",
      "Prediction: Fm\n",
      "9/153: .\\test\\mi2023_key-meter_test_008.mid\n",
      "Prediction: E\n",
      "10/153: .\\test\\mi2023_key-meter_test_009.mid\n",
      "Prediction: D#m\n",
      "11/153: .\\test\\mi2023_key-meter_test_010.mid\n",
      "Prediction: C\n",
      "12/153: .\\test\\mi2023_key-meter_test_011.mid\n",
      "Prediction: Ab\n",
      "13/153: .\\test\\mi2023_key-meter_test_012.mid\n",
      "Prediction: E\n",
      "14/153: .\\test\\mi2023_key-meter_test_013.mid\n",
      "Prediction: Ab\n",
      "15/153: .\\test\\mi2023_key-meter_test_014.mid\n",
      "Prediction: F#m\n",
      "16/153: .\\test\\mi2023_key-meter_test_015.mid\n",
      "Prediction: Ab\n",
      "17/153: .\\test\\mi2023_key-meter_test_016.mid\n",
      "Prediction: Db\n",
      "18/153: .\\test\\mi2023_key-meter_test_017.mid\n",
      "Prediction: A\n",
      "19/153: .\\test\\mi2023_key-meter_test_018.mid\n",
      "Prediction: Ab\n",
      "20/153: .\\test\\mi2023_key-meter_test_019.mid\n",
      "Prediction: Cm\n",
      "21/153: .\\test\\mi2023_key-meter_test_020.mid\n",
      "Prediction: F#\n",
      "22/153: .\\test\\mi2023_key-meter_test_021.mid\n",
      "Prediction: D#m\n",
      "23/153: .\\test\\mi2023_key-meter_test_022.mid\n",
      "Prediction: Em\n",
      "24/153: .\\test\\mi2023_key-meter_test_023.mid\n",
      "Prediction: F\n",
      "25/153: .\\test\\mi2023_key-meter_test_024.mid\n",
      "Prediction: C\n",
      "26/153: .\\test\\mi2023_key-meter_test_025.mid\n",
      "Prediction: F\n",
      "27/153: .\\test\\mi2023_key-meter_test_026.mid\n",
      "Prediction: Cm\n",
      "28/153: .\\test\\mi2023_key-meter_test_027.mid\n",
      "Prediction: Cm\n",
      "29/153: .\\test\\mi2023_key-meter_test_028.mid\n",
      "Prediction: Cm\n",
      "30/153: .\\test\\mi2023_key-meter_test_029.mid\n",
      "Prediction: Fm\n",
      "31/153: .\\test\\mi2023_key-meter_test_030.mid\n",
      "Prediction: Fm\n",
      "32/153: .\\test\\mi2023_key-meter_test_031.mid\n",
      "Prediction: C#m\n",
      "33/153: .\\test\\mi2023_key-meter_test_032.mid\n",
      "Prediction: E\n",
      "34/153: .\\test\\mi2023_key-meter_test_033.mid\n",
      "Prediction: A\n",
      "35/153: .\\test\\mi2023_key-meter_test_034.mid\n",
      "Prediction: Bbm\n",
      "36/153: .\\test\\mi2023_key-meter_test_035.mid\n",
      "Prediction: C\n",
      "37/153: .\\test\\mi2023_key-meter_test_036.mid\n",
      "Prediction: F\n",
      "38/153: .\\test\\mi2023_key-meter_test_037.mid\n",
      "Prediction: F#m\n",
      "39/153: .\\test\\mi2023_key-meter_test_038.mid\n",
      "Prediction: Em\n",
      "40/153: .\\test\\mi2023_key-meter_test_039.mid\n",
      "Prediction: C#m\n",
      "41/153: .\\test\\mi2023_key-meter_test_040.mid\n",
      "Prediction: Am\n",
      "42/153: .\\test\\mi2023_key-meter_test_041.mid\n",
      "Prediction: F\n",
      "43/153: .\\test\\mi2023_key-meter_test_042.mid\n",
      "Prediction: Fm\n",
      "44/153: .\\test\\mi2023_key-meter_test_043.mid\n",
      "Prediction: Fm\n",
      "45/153: .\\test\\mi2023_key-meter_test_044.mid\n",
      "Prediction: Am\n",
      "46/153: .\\test\\mi2023_key-meter_test_045.mid\n",
      "Prediction: F#\n",
      "47/153: .\\test\\mi2023_key-meter_test_046.mid\n",
      "Prediction: C#m\n",
      "48/153: .\\test\\mi2023_key-meter_test_047.mid\n",
      "Prediction: Am\n",
      "49/153: .\\test\\mi2023_key-meter_test_048.mid\n",
      "Prediction: Ab\n",
      "50/153: .\\test\\mi2023_key-meter_test_049.mid\n",
      "Prediction: Am\n",
      "51/153: .\\test\\mi2023_key-meter_test_050.mid\n",
      "Prediction: C#m\n",
      "52/153: .\\test\\mi2023_key-meter_test_051.mid\n",
      "Prediction: F#\n",
      "53/153: .\\test\\mi2023_key-meter_test_052.mid\n",
      "Prediction: C\n",
      "54/153: .\\test\\mi2023_key-meter_test_053.mid\n",
      "Prediction: Fm\n",
      "55/153: .\\test\\mi2023_key-meter_test_054.mid\n",
      "Prediction: Eb\n",
      "56/153: .\\test\\mi2023_key-meter_test_055.mid\n",
      "Prediction: Eb\n",
      "57/153: .\\test\\mi2023_key-meter_test_056.mid\n",
      "Prediction: C#m\n",
      "58/153: .\\test\\mi2023_key-meter_test_057.mid\n",
      "Prediction: C#m\n",
      "59/153: .\\test\\mi2023_key-meter_test_058.mid\n",
      "Prediction: F\n",
      "60/153: .\\test\\mi2023_key-meter_test_059.mid\n",
      "Prediction: Eb\n",
      "61/153: .\\test\\mi2023_key-meter_test_060.mid\n",
      "Prediction: Eb\n",
      "62/153: .\\test\\mi2023_key-meter_test_061.mid\n",
      "Prediction: E\n",
      "63/153: .\\test\\mi2023_key-meter_test_062.mid\n",
      "Prediction: Am\n",
      "64/153: .\\test\\mi2023_key-meter_test_063.mid\n",
      "Prediction: Em\n",
      "65/153: .\\test\\mi2023_key-meter_test_064.mid\n",
      "Prediction: C\n",
      "66/153: .\\test\\mi2023_key-meter_test_065.mid\n",
      "Prediction: Fm\n",
      "67/153: .\\test\\mi2023_key-meter_test_066.mid\n",
      "Prediction: Cm\n",
      "68/153: .\\test\\mi2023_key-meter_test_067.mid\n",
      "Prediction: Gm\n",
      "69/153: .\\test\\mi2023_key-meter_test_068.mid\n",
      "Prediction: Am\n",
      "70/153: .\\test\\mi2023_key-meter_test_069.mid\n",
      "Prediction: C#m\n",
      "71/153: .\\test\\mi2023_key-meter_test_070.mid\n",
      "Prediction: Gm\n",
      "72/153: .\\test\\mi2023_key-meter_test_071.mid\n",
      "Prediction: Db\n",
      "73/153: .\\test\\mi2023_key-meter_test_072.mid\n",
      "Prediction: F\n",
      "74/153: .\\test\\mi2023_key-meter_test_073.mid\n",
      "Prediction: Eb\n",
      "75/153: .\\test\\mi2023_key-meter_test_074.mid\n",
      "Prediction: C#m\n",
      "76/153: .\\test\\mi2023_key-meter_test_075.mid\n",
      "Prediction: Bb\n",
      "77/153: .\\test\\mi2023_key-meter_test_076.mid\n",
      "Prediction: C\n",
      "78/153: .\\test\\mi2023_key-meter_test_077.mid\n",
      "Prediction: F\n",
      "79/153: .\\test\\mi2023_key-meter_test_078.mid\n",
      "Prediction: F#\n",
      "80/153: .\\test\\mi2023_key-meter_test_079.mid\n",
      "Prediction: Eb\n",
      "81/153: .\\test\\mi2023_key-meter_test_080.mid\n",
      "Prediction: F\n",
      "82/153: .\\test\\mi2023_key-meter_test_081.mid\n",
      "Prediction: C\n",
      "83/153: .\\test\\mi2023_key-meter_test_082.mid\n",
      "Prediction: Ab\n",
      "84/153: .\\test\\mi2023_key-meter_test_083.mid\n",
      "Prediction: D\n",
      "85/153: .\\test\\mi2023_key-meter_test_084.mid\n",
      "Prediction: G\n",
      "86/153: .\\test\\mi2023_key-meter_test_085.mid\n",
      "Prediction: Dm\n",
      "87/153: .\\test\\mi2023_key-meter_test_086.mid\n",
      "Prediction: Am\n",
      "88/153: .\\test\\mi2023_key-meter_test_087.mid\n",
      "Prediction: D#m\n",
      "89/153: .\\test\\mi2023_key-meter_test_088.mid\n",
      "Prediction: Dm\n",
      "90/153: .\\test\\mi2023_key-meter_test_089.mid\n",
      "Prediction: Em\n",
      "91/153: .\\test\\mi2023_key-meter_test_090.mid\n",
      "Prediction: Am\n",
      "92/153: .\\test\\mi2023_key-meter_test_091.mid\n",
      "Prediction: Db\n",
      "93/153: .\\test\\mi2023_key-meter_test_092.mid\n",
      "Prediction: C#m\n",
      "94/153: .\\test\\mi2023_key-meter_test_093.mid\n",
      "Prediction: Db\n",
      "95/153: .\\test\\mi2023_key-meter_test_094.mid\n",
      "Prediction: E\n",
      "96/153: .\\test\\mi2023_key-meter_test_095.mid\n",
      "Prediction: Bbm\n",
      "97/153: .\\test\\mi2023_key-meter_test_096.mid\n",
      "Prediction: Am\n",
      "98/153: .\\test\\mi2023_key-meter_test_097.mid\n",
      "Prediction: Ab\n",
      "99/153: .\\test\\mi2023_key-meter_test_098.mid\n",
      "Prediction: G#m\n",
      "100/153: .\\test\\mi2023_key-meter_test_099.mid\n",
      "Prediction: G#m\n",
      "101/153: .\\test\\mi2023_key-meter_test_100.mid\n",
      "Prediction: Am\n",
      "102/153: .\\test\\mi2023_key-meter_test_101.mid\n",
      "Prediction: Fm\n",
      "103/153: .\\test\\mi2023_key-meter_test_102.mid\n",
      "Prediction: Ab\n",
      "104/153: .\\test\\mi2023_key-meter_test_103.mid\n",
      "Prediction: D\n",
      "105/153: .\\test\\mi2023_key-meter_test_104.mid\n",
      "Prediction: Bb\n",
      "106/153: .\\test\\mi2023_key-meter_test_105.mid\n",
      "Prediction: Ab\n",
      "107/153: .\\test\\mi2023_key-meter_test_106.mid\n",
      "Prediction: Fm\n",
      "108/153: .\\test\\mi2023_key-meter_test_107.mid\n",
      "Prediction: Cm\n",
      "109/153: .\\test\\mi2023_key-meter_test_108.mid\n",
      "Prediction: Em\n",
      "110/153: .\\test\\mi2023_key-meter_test_109.mid\n",
      "Prediction: Cm\n",
      "111/153: .\\test\\mi2023_key-meter_test_110.mid\n",
      "Prediction: C#m\n",
      "112/153: .\\test\\mi2023_key-meter_test_111.mid\n",
      "Prediction: Em\n",
      "113/153: .\\test\\mi2023_key-meter_test_112.mid\n",
      "Prediction: Am\n",
      "114/153: .\\test\\mi2023_key-meter_test_113.mid\n",
      "Prediction: G#m\n",
      "115/153: .\\test\\mi2023_key-meter_test_114.mid\n",
      "Prediction: Ab\n",
      "116/153: .\\test\\mi2023_key-meter_test_115.mid\n",
      "Prediction: F\n",
      "117/153: .\\test\\mi2023_key-meter_test_116.mid\n",
      "Prediction: Am\n",
      "118/153: .\\test\\mi2023_key-meter_test_117.mid\n",
      "Prediction: F#\n",
      "119/153: .\\test\\mi2023_key-meter_test_118.mid\n",
      "Prediction: F#\n",
      "120/153: .\\test\\mi2023_key-meter_test_119.mid\n",
      "Prediction: F\n",
      "121/153: .\\test\\mi2023_key-meter_test_120.mid\n",
      "Prediction: G\n",
      "122/153: .\\test\\mi2023_key-meter_test_121.mid\n",
      "Prediction: C\n",
      "123/153: .\\test\\mi2023_key-meter_test_122.mid\n",
      "Prediction: F\n",
      "124/153: .\\test\\mi2023_key-meter_test_123.mid\n",
      "Prediction: D#m\n",
      "125/153: .\\test\\mi2023_key-meter_test_124.mid\n",
      "Prediction: E\n",
      "126/153: .\\test\\mi2023_key-meter_test_125.mid\n",
      "Prediction: C\n",
      "127/153: .\\test\\mi2023_key-meter_test_126.mid\n",
      "Prediction: B\n",
      "128/153: .\\test\\mi2023_key-meter_test_127.mid\n",
      "Prediction: F#\n",
      "129/153: .\\test\\mi2023_key-meter_test_128.mid\n",
      "Prediction: C\n",
      "130/153: .\\test\\mi2023_key-meter_test_129.mid\n",
      "Prediction: Ab\n",
      "131/153: .\\test\\mi2023_key-meter_test_130.mid\n",
      "Prediction: F#\n",
      "132/153: .\\test\\mi2023_key-meter_test_131.mid\n",
      "Prediction: Db\n",
      "133/153: .\\test\\mi2023_key-meter_test_132.mid\n",
      "Prediction: F#\n",
      "134/153: .\\test\\mi2023_key-meter_test_133.mid\n",
      "Prediction: F#\n",
      "135/153: .\\test\\mi2023_key-meter_test_134.mid\n",
      "Prediction: D#m\n",
      "136/153: .\\test\\mi2023_key-meter_test_135.mid\n",
      "Prediction: Bm\n",
      "137/153: .\\test\\mi2023_key-meter_test_136.mid\n",
      "Prediction: C#m\n",
      "138/153: .\\test\\mi2023_key-meter_test_137.mid\n",
      "Prediction: Db\n",
      "139/153: .\\test\\mi2023_key-meter_test_138.mid\n",
      "Prediction: F#m\n",
      "140/153: .\\test\\mi2023_key-meter_test_139.mid\n",
      "Prediction: E\n",
      "141/153: .\\test\\mi2023_key-meter_test_140.mid\n",
      "Prediction: Ab\n",
      "142/153: .\\test\\mi2023_key-meter_test_141.mid\n",
      "Prediction: Fm\n",
      "143/153: .\\test\\mi2023_key-meter_test_142.mid\n",
      "Prediction: Ab\n",
      "144/153: .\\test\\mi2023_key-meter_test_143.mid\n",
      "Prediction: C\n",
      "145/153: .\\test\\mi2023_key-meter_test_144.mid\n",
      "Prediction: Am\n",
      "146/153: .\\test\\mi2023_key-meter_test_145.mid\n",
      "Prediction: F#\n",
      "147/153: .\\test\\mi2023_key-meter_test_146.mid\n",
      "Prediction: Am\n",
      "148/153: .\\test\\mi2023_key-meter_test_147.mid\n",
      "Prediction: Db\n",
      "149/153: .\\test\\mi2023_key-meter_test_148.mid\n",
      "Prediction: C#m\n",
      "150/153: .\\test\\mi2023_key-meter_test_149.mid\n",
      "Prediction: D#m\n",
      "151/153: .\\test\\mi2023_key-meter_test_150.mid\n",
      "Prediction: F\n",
      "152/153: .\\test\\mi2023_key-meter_test_151.mid\n",
      "Prediction: Em\n",
      "153/153: .\\test\\mi2023_key-meter_test_152.mid\n",
      "Prediction: Fm\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class KeyPredictionArgs:\n",
    "    datadir = os.path.join('.', 'test')\n",
    "    modeldir = '.' # insert path to our saved model here\n",
    "    \n",
    "args = KeyPredictionArgs()\n",
    "\n",
    "midi_files = glob.glob(os.path.join(args.datadir, \"*.mid\"))\n",
    "midi_files.sort()\n",
    "\n",
    "# Create time and key processors\n",
    "processor_key_sig = RNNKeySignatureProcessor(os.path.join(args.modeldir, '_model_state_dicts', 'key_signature', 'RNNKeySignatureModel.pth'))\n",
    "\n",
    "results = []\n",
    "# Prediction\n",
    "for idx, file in enumerate(midi_files):\n",
    "    p = pt.load_performance_midi(Path(file))\n",
    "    note_array = p.note_array()\n",
    "    note_sequence = np.array(list(zip(note_array['pitch'], note_array['onset_sec'], note_array['duration_sec'], note_array['velocity'])))\n",
    "\n",
    "    key_signature_changes = processor_key_sig.process(note_sequence)\n",
    "\n",
    "    length = note_sequence[-1][1] + note_sequence[-1][2]\n",
    "\n",
    "    last_onset, last_key = key_signature_changes[0]\n",
    "    durations = {}\n",
    "    for onset, key in key_signature_changes[1:]:\n",
    "        if last_key not in durations.keys():\n",
    "            durations[last_key] = 0\n",
    "        durations[last_key] += onset - last_onset\n",
    "        last_onset = onset\n",
    "        last_key = key\n",
    "    if last_key not in durations.keys():\n",
    "        durations[last_key] = 0\n",
    "    durations[last_key] += length - last_onset\n",
    "\n",
    "    best_duration, best_key = 0, 0\n",
    "    for key, duration in durations.items():\n",
    "        if duration > best_duration:\n",
    "            best_duration = duration\n",
    "            best_key = key\n",
    "\n",
    "    print(f\"{str(idx + 1)}/{str(len(midi_files))}: {file}\")\n",
    "    print(\"Prediction: \" + str(best_key))\n",
    "\n",
    "    results.append((os.path.basename(file), best_key))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:39:22.495587900Z",
     "start_time": "2024-01-08T13:34:33.997215Z"
    }
   },
   "id": "60f1f5c283fce51"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "This model, when applied to our data, is able to solve this challenge in a satisfying manner as our team is placed number 1 on the leaderboard (as of January 8th). After a couple of hours of training (about 13 epochs), we already achieved an f-score of 0.97, but this score must be taken with a grain of salt as the verification is done with pieces from the training set. We reached an average tonal distance of 0.379, which tells us that our model is right most of the time, and if it does not output the right key it is probably not that far off, i.e. a C major key is wrongly detected as an A minor key, which uses the same notes but has a different root."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca316e65ae461da7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Meter estimation challenge\n",
    "\n",
    "Very similarly to the key estimation challenge, the meter estimation challenge is about processing performed pieces to calculate which meter the piece is written in, e.g. 4/4 or 3/4. But this challenge only takes the numerator into account because the challenge already is quite hard. The provided dataset is the same as the dataset for the key estimation challenge, and our solution also uses many components that have been seen in the above paragraphs. Therefore, it is required to execute the code above for this part to work. \n",
    "\n",
    "At first, we will only look at the meter, not the tempo."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "986710b7b828b5d5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset\n",
    "\n",
    "This part is nearly a carbon copy of the one above, so we will just create the classes without further elaboration."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ccf7c5e30a7fd50"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "class TimeSignatureDataset(BaseDataset):\n",
    "\n",
    "    def __init__(self, workspace, split):\n",
    "        super().__init__(workspace, split)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        row = self._sample_row(idx)\n",
    "        note_sequence, annotations = self._load_data(row)\n",
    "\n",
    "        # Get model output data\n",
    "        time_signatures = annotations['time_signatures']\n",
    "        ts_numerators = np.zeros(len(note_sequence)).astype(float)\n",
    "\n",
    "        for i in range(len(note_sequence)):\n",
    "            onset = note_sequence[i, 1]\n",
    "            for ts in time_signatures:\n",
    "                if ts[0] > onset + tolerance:\n",
    "                    break\n",
    "                ts_numerators[i] = tsNume2Index[int(ts[1])] if int(ts[1]) in tsNume2Index.keys() else 0\n",
    "\n",
    "        # padding\n",
    "        length = len(note_sequence)\n",
    "        if length < max_length:\n",
    "            note_sequence = np.concatenate([note_sequence, np.zeros((max_length - length, 4))])\n",
    "            ts_numerators = np.concatenate([ts_numerators, np.zeros(max_length - length)])\n",
    "\n",
    "        return note_sequence, ts_numerators, length"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:39:51.391894900Z",
     "start_time": "2024-01-08T13:39:51.326989800Z"
    }
   },
   "id": "61d72ca5e55f52aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Recurrent Neural Network\n",
    "\n",
    "The RNN model as well as the module wrapper is also the same as for the key estimation challenge, the only difference being the last layer, which of course has to provide different (less) classes as an output."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c909756b92cd0bf3"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "class RNNTimeSignatureModel(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size=512):\n",
    "        super().__init__()\n",
    "\n",
    "        in_features = get_in_features()\n",
    "\n",
    "        self.convs = ConvBlock(in_features=in_features)\n",
    "        self.gru = GRUBlock(in_features=hidden_size)\n",
    "        self.out_tn = LinearOutput(in_features=hidden_size, out_features=tsNumeVocabSize, activation_type='softmax')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, len(features)==4)\n",
    "        x = encode_note_sequence(x)\n",
    "\n",
    "        x = self.convs(x)  # (batch_size, seq_len, hidden_size)\n",
    "\n",
    "        x_gru = self.gru(x)  # (batch_size, seq_len, hidden_size)\n",
    "        y_tn = self.out_tn(x_gru)  # (batch_size, seq_len, tsNumeVocabSize)\n",
    "        y_tn = y_tn.permute(0, 2, 1)  # (batch_size, tsNumeVocabSize, seq_len)\n",
    "\n",
    "        return y_tn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:39:53.737488500Z",
     "start_time": "2024-01-08T13:39:53.689615400Z"
    }
   },
   "id": "70f6c0e5d25e95f4"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "class TimeSignatureModule(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = RNNTimeSignatureModel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return configure_optimizers(self)\n",
    "\n",
    "    def configure_callbacks(self):\n",
    "        return configure_callbacks(monitor='val_f1')\n",
    "\n",
    "    def training_step(self, batch, batch_size):\n",
    "        # Data\n",
    "        x, y_tn, length = batch\n",
    "        x = x.float()\n",
    "        y_tn = y_tn.long()\n",
    "        length = length.long()\n",
    "\n",
    "        # Forward pass\n",
    "        y_tn_hat = self(x)\n",
    "\n",
    "        # Mask out the padding part\n",
    "        pad_mask = torch.ones((y_tn_hat.shape[0], y_tn_hat.shape[2])).to(y_tn_hat.device)\n",
    "        for i in range(y_tn_hat.shape[0]):\n",
    "            pad_mask[i, length[i]:] = 0\n",
    "        y_tn_hat = y_tn_hat * pad_mask.unsqueeze(1)\n",
    "\n",
    "        # Loss\n",
    "        loss = nn.NLLLoss(ignore_index=0)(y_tn_hat, y_tn)\n",
    "\n",
    "        # Logging\n",
    "        logs = {\n",
    "            'train_loss': loss,\n",
    "        }\n",
    "        self.log_dict(logs, prog_bar=True)\n",
    "\n",
    "        return {'loss': loss, 'logs': logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_size):\n",
    "        # Data\n",
    "        x, y_tn, length = batch\n",
    "        x = x.float()\n",
    "        y_tn = y_tn.long()\n",
    "        length = length.long()\n",
    "\n",
    "        # Forward pass\n",
    "        y_tn_hat = self(x)\n",
    "\n",
    "        # Mask out the padding part\n",
    "        for i in range(y_tn_hat.shape[0]):\n",
    "            y_tn_hat[i, :, length[i]:] = 0\n",
    "\n",
    "        # Loss\n",
    "        loss = nn.NLLLoss(ignore_index=0)(y_tn_hat, y_tn)\n",
    "\n",
    "        # Metrics\n",
    "        fs_macro_tn = 0\n",
    "\n",
    "        for i in range(x.shape[0]):\n",
    "            # get sample from batch\n",
    "            y_tn_hat_i = y_tn_hat[i, :, :length[i]].topk(1, dim=0)[1][0]\n",
    "            y_tn_i = y_tn[i, :length[i]]\n",
    "\n",
    "            # filter out ignored indexes (the same as padding)\n",
    "            y_tn_hat_i = y_tn_hat_i[y_tn_i != 0]\n",
    "            y_tn_i = y_tn_i[y_tn_i != 0]\n",
    "\n",
    "            # get accuracies\n",
    "            (\n",
    "                _, _, f_macro_tn,\n",
    "                _, _, _\n",
    "            ) = classification_report_framewise(y_tn_i, y_tn_hat_i)\n",
    "\n",
    "            fs_macro_tn += f_macro_tn\n",
    "\n",
    "        fs_macro_tn /= x.shape[0]\n",
    "\n",
    "        # Logging\n",
    "        logs = {\n",
    "            'val_loss': loss,\n",
    "            'val_f1': fs_macro_tn,\n",
    "        }\n",
    "        self.log_dict(logs, prog_bar=True)\n",
    "\n",
    "        return {'loss': loss, 'logs': logs}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:39:54.498225100Z",
     "start_time": "2024-01-08T13:39:54.436391900Z"
    }
   },
   "id": "4661321241b1fa9c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "\n",
    "Now, let's train the model!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8c6bd22f39546c9"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                  | Params\n",
      "------------------------------------------------\n",
      "0 | model | RNNTimeSignatureModel | 10.5 M\n",
      "------------------------------------------------\n",
      "10.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.5 M    Total params\n",
      "41.976    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f8b9fd1022c449789c0377706bde151"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e60441de0628410d9b6e8e9b79eda876"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad74b82d9dd74bd9bc92dbee9646ef12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b16b1c05bf944767998e7de75d7df3a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MeterTrainArgs:\n",
    "    workspace = os.path.join('.', 'train') # set to your workspace which contains the dataset\n",
    "    feature = 'time_signature'\n",
    "    full_train = True\n",
    "\n",
    "train(MeterTrainArgs())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:48:04.704256200Z",
     "start_time": "2024-01-08T13:40:38.098364900Z"
    }
   },
   "id": "2dacf1ad364452a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model saving\n",
    "Now, let's save the model again."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc96b911c66fb5a0"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "class MeterSaveArgs:\n",
    "    model_checkpoint_path = os.path.join('.', 'mlruns', 'lightning_logs', 'version_2', 'checkpoints', 'last.ckpt') # insert path your trained model here\n",
    "    feature = 'time_signature'\n",
    "\n",
    "save_model(MeterSaveArgs())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:49:11.906468900Z",
     "start_time": "2024-01-08T13:49:11.164997300Z"
    }
   },
   "id": "cc86980f8e5bd585"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction\n",
    "Yet again, we employ the same technique as we did when solving the key estimation challenge. The RNN outputs a list of time signature changes, and we aggregate them to find the time signature that is predicted for the longest duration."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8ced3253a09191c"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "class RNNTimeSignatureProcessor(MIDIProcessor):\n",
    "\n",
    "    def __init__(self, model_state_dict_path='_model_state_dicts/time_signature/RNNTimeSignatureModel.pth', **kwargs):\n",
    "        super().__init__(model_state_dict_path, **kwargs)\n",
    "\n",
    "    def load(self, state_dict_path):\n",
    "        if state_dict_path:\n",
    "            self._model = RNNTimeSignatureModel()\n",
    "            self._model.load_state_dict(torch.load(state_dict_path))\n",
    "        else:\n",
    "            self._model = RNNTimeSignatureModel()\n",
    "\n",
    "    def process(self, note_seq, **kwargs):\n",
    "        x = torch.tensor(note_seq).unsqueeze(0)\n",
    "\n",
    "        # Forward pass\n",
    "        tn_probs = self._model(x)\n",
    "\n",
    "        # Post-processing\n",
    "        tn_idx = tn_probs[0].topk(1, dim=0)[1].squeeze(0).cpu().detach().numpy() # (seq_len,)\n",
    "\n",
    "        onsets = note_seq[:, 1]\n",
    "        time_signature_changes = self.pps(tn_idx, onsets)\n",
    "\n",
    "        return time_signature_changes\n",
    "\n",
    "    def pps(self, tn_idx, onsets):\n",
    "        ts_prev = '0/0'\n",
    "        ts_changes = []\n",
    "        for i in range(len(tn_idx)):\n",
    "            ts_cur = '{:d}'.format(tsIndex2Nume[tn_idx[i]])\n",
    "            if i == 0 or ts_cur != ts_prev:\n",
    "                onset_cur = onsets[i]\n",
    "                ts_changes.append((onset_cur, ts_cur))\n",
    "                ts_prev = ts_cur\n",
    "        return ts_changes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:49:25.072947300Z",
     "start_time": "2024-01-08T13:49:25.037043900Z"
    }
   },
   "id": "d0672c37b2e760d0"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/153: .\\test\\mi2023_key-meter_test_000.mid\n",
      "Prediction: 2\n",
      "2/153: .\\test\\mi2023_key-meter_test_001.mid\n",
      "Prediction: 4\n",
      "3/153: .\\test\\mi2023_key-meter_test_002.mid\n",
      "Prediction: 2\n",
      "4/153: .\\test\\mi2023_key-meter_test_003.mid\n",
      "Prediction: 4\n",
      "5/153: .\\test\\mi2023_key-meter_test_004.mid\n",
      "Prediction: 2\n",
      "6/153: .\\test\\mi2023_key-meter_test_005.mid\n",
      "Prediction: 3\n",
      "7/153: .\\test\\mi2023_key-meter_test_006.mid\n",
      "Prediction: 4\n",
      "8/153: .\\test\\mi2023_key-meter_test_007.mid\n",
      "Prediction: 4\n",
      "9/153: .\\test\\mi2023_key-meter_test_008.mid\n",
      "Prediction: 4\n",
      "10/153: .\\test\\mi2023_key-meter_test_009.mid\n",
      "Prediction: 4\n",
      "11/153: .\\test\\mi2023_key-meter_test_010.mid\n",
      "Prediction: 4\n",
      "12/153: .\\test\\mi2023_key-meter_test_011.mid\n",
      "Prediction: 4\n",
      "13/153: .\\test\\mi2023_key-meter_test_012.mid\n",
      "Prediction: 4\n",
      "14/153: .\\test\\mi2023_key-meter_test_013.mid\n",
      "Prediction: 4\n",
      "15/153: .\\test\\mi2023_key-meter_test_014.mid\n",
      "Prediction: 4\n",
      "16/153: .\\test\\mi2023_key-meter_test_015.mid\n",
      "Prediction: 4\n",
      "17/153: .\\test\\mi2023_key-meter_test_016.mid\n",
      "Prediction: 2\n",
      "18/153: .\\test\\mi2023_key-meter_test_017.mid\n",
      "Prediction: 6\n",
      "19/153: .\\test\\mi2023_key-meter_test_018.mid\n",
      "Prediction: 4\n",
      "20/153: .\\test\\mi2023_key-meter_test_019.mid\n",
      "Prediction: 4\n",
      "21/153: .\\test\\mi2023_key-meter_test_020.mid\n",
      "Prediction: 4\n",
      "22/153: .\\test\\mi2023_key-meter_test_021.mid\n",
      "Prediction: 4\n",
      "23/153: .\\test\\mi2023_key-meter_test_022.mid\n",
      "Prediction: 4\n",
      "24/153: .\\test\\mi2023_key-meter_test_023.mid\n",
      "Prediction: 4\n",
      "25/153: .\\test\\mi2023_key-meter_test_024.mid\n",
      "Prediction: 4\n",
      "26/153: .\\test\\mi2023_key-meter_test_025.mid\n",
      "Prediction: 2\n",
      "27/153: .\\test\\mi2023_key-meter_test_026.mid\n",
      "Prediction: 2\n",
      "28/153: .\\test\\mi2023_key-meter_test_027.mid\n",
      "Prediction: 2\n",
      "29/153: .\\test\\mi2023_key-meter_test_028.mid\n",
      "Prediction: 4\n",
      "30/153: .\\test\\mi2023_key-meter_test_029.mid\n",
      "Prediction: 4\n",
      "31/153: .\\test\\mi2023_key-meter_test_030.mid\n",
      "Prediction: 4\n",
      "32/153: .\\test\\mi2023_key-meter_test_031.mid\n",
      "Prediction: 6\n",
      "33/153: .\\test\\mi2023_key-meter_test_032.mid\n",
      "Prediction: 2\n",
      "34/153: .\\test\\mi2023_key-meter_test_033.mid\n",
      "Prediction: 4\n",
      "35/153: .\\test\\mi2023_key-meter_test_034.mid\n",
      "Prediction: 4\n",
      "36/153: .\\test\\mi2023_key-meter_test_035.mid\n",
      "Prediction: 3\n",
      "37/153: .\\test\\mi2023_key-meter_test_036.mid\n",
      "Prediction: 6\n",
      "38/153: .\\test\\mi2023_key-meter_test_037.mid\n",
      "Prediction: 4\n",
      "39/153: .\\test\\mi2023_key-meter_test_038.mid\n",
      "Prediction: 2\n",
      "40/153: .\\test\\mi2023_key-meter_test_039.mid\n",
      "Prediction: 4\n",
      "41/153: .\\test\\mi2023_key-meter_test_040.mid\n",
      "Prediction: 4\n",
      "42/153: .\\test\\mi2023_key-meter_test_041.mid\n",
      "Prediction: 3\n",
      "43/153: .\\test\\mi2023_key-meter_test_042.mid\n",
      "Prediction: 9\n",
      "44/153: .\\test\\mi2023_key-meter_test_043.mid\n",
      "Prediction: 4\n",
      "45/153: .\\test\\mi2023_key-meter_test_044.mid\n",
      "Prediction: 4\n",
      "46/153: .\\test\\mi2023_key-meter_test_045.mid\n",
      "Prediction: 3\n",
      "47/153: .\\test\\mi2023_key-meter_test_046.mid\n",
      "Prediction: 2\n",
      "48/153: .\\test\\mi2023_key-meter_test_047.mid\n",
      "Prediction: 2\n",
      "49/153: .\\test\\mi2023_key-meter_test_048.mid\n",
      "Prediction: 4\n",
      "50/153: .\\test\\mi2023_key-meter_test_049.mid\n",
      "Prediction: 4\n",
      "51/153: .\\test\\mi2023_key-meter_test_050.mid\n",
      "Prediction: 2\n",
      "52/153: .\\test\\mi2023_key-meter_test_051.mid\n",
      "Prediction: 2\n",
      "53/153: .\\test\\mi2023_key-meter_test_052.mid\n",
      "Prediction: 4\n",
      "54/153: .\\test\\mi2023_key-meter_test_053.mid\n",
      "Prediction: 4\n",
      "55/153: .\\test\\mi2023_key-meter_test_054.mid\n",
      "Prediction: 2\n",
      "56/153: .\\test\\mi2023_key-meter_test_055.mid\n",
      "Prediction: 4\n",
      "57/153: .\\test\\mi2023_key-meter_test_056.mid\n",
      "Prediction: 4\n",
      "58/153: .\\test\\mi2023_key-meter_test_057.mid\n",
      "Prediction: 4\n",
      "59/153: .\\test\\mi2023_key-meter_test_058.mid\n",
      "Prediction: 4\n",
      "60/153: .\\test\\mi2023_key-meter_test_059.mid\n",
      "Prediction: 3\n",
      "61/153: .\\test\\mi2023_key-meter_test_060.mid\n",
      "Prediction: 2\n",
      "62/153: .\\test\\mi2023_key-meter_test_061.mid\n",
      "Prediction: 4\n",
      "63/153: .\\test\\mi2023_key-meter_test_062.mid\n",
      "Prediction: 2\n",
      "64/153: .\\test\\mi2023_key-meter_test_063.mid\n",
      "Prediction: 4\n",
      "65/153: .\\test\\mi2023_key-meter_test_064.mid\n",
      "Prediction: 4\n",
      "66/153: .\\test\\mi2023_key-meter_test_065.mid\n",
      "Prediction: 4\n",
      "67/153: .\\test\\mi2023_key-meter_test_066.mid\n",
      "Prediction: 2\n",
      "68/153: .\\test\\mi2023_key-meter_test_067.mid\n",
      "Prediction: 4\n",
      "69/153: .\\test\\mi2023_key-meter_test_068.mid\n",
      "Prediction: 3\n",
      "70/153: .\\test\\mi2023_key-meter_test_069.mid\n",
      "Prediction: 2\n",
      "71/153: .\\test\\mi2023_key-meter_test_070.mid\n",
      "Prediction: 4\n",
      "72/153: .\\test\\mi2023_key-meter_test_071.mid\n",
      "Prediction: 2\n",
      "73/153: .\\test\\mi2023_key-meter_test_072.mid\n",
      "Prediction: 3\n",
      "74/153: .\\test\\mi2023_key-meter_test_073.mid\n",
      "Prediction: 4\n",
      "75/153: .\\test\\mi2023_key-meter_test_074.mid\n",
      "Prediction: 4\n",
      "76/153: .\\test\\mi2023_key-meter_test_075.mid\n",
      "Prediction: 6\n",
      "77/153: .\\test\\mi2023_key-meter_test_076.mid\n",
      "Prediction: 4\n",
      "78/153: .\\test\\mi2023_key-meter_test_077.mid\n",
      "Prediction: 2\n",
      "79/153: .\\test\\mi2023_key-meter_test_078.mid\n",
      "Prediction: 2\n",
      "80/153: .\\test\\mi2023_key-meter_test_079.mid\n",
      "Prediction: 3\n",
      "81/153: .\\test\\mi2023_key-meter_test_080.mid\n",
      "Prediction: 2\n",
      "82/153: .\\test\\mi2023_key-meter_test_081.mid\n",
      "Prediction: 4\n",
      "83/153: .\\test\\mi2023_key-meter_test_082.mid\n",
      "Prediction: 4\n",
      "84/153: .\\test\\mi2023_key-meter_test_083.mid\n",
      "Prediction: 4\n",
      "85/153: .\\test\\mi2023_key-meter_test_084.mid\n",
      "Prediction: 4\n",
      "86/153: .\\test\\mi2023_key-meter_test_085.mid\n",
      "Prediction: 4\n",
      "87/153: .\\test\\mi2023_key-meter_test_086.mid\n",
      "Prediction: 2\n",
      "88/153: .\\test\\mi2023_key-meter_test_087.mid\n",
      "Prediction: 4\n",
      "89/153: .\\test\\mi2023_key-meter_test_088.mid\n",
      "Prediction: 4\n",
      "90/153: .\\test\\mi2023_key-meter_test_089.mid\n",
      "Prediction: 4\n",
      "91/153: .\\test\\mi2023_key-meter_test_090.mid\n",
      "Prediction: 4\n",
      "92/153: .\\test\\mi2023_key-meter_test_091.mid\n",
      "Prediction: 4\n",
      "93/153: .\\test\\mi2023_key-meter_test_092.mid\n",
      "Prediction: 2\n",
      "94/153: .\\test\\mi2023_key-meter_test_093.mid\n",
      "Prediction: 2\n",
      "95/153: .\\test\\mi2023_key-meter_test_094.mid\n",
      "Prediction: 4\n",
      "96/153: .\\test\\mi2023_key-meter_test_095.mid\n",
      "Prediction: 4\n",
      "97/153: .\\test\\mi2023_key-meter_test_096.mid\n",
      "Prediction: 4\n",
      "98/153: .\\test\\mi2023_key-meter_test_097.mid\n",
      "Prediction: 4\n",
      "99/153: .\\test\\mi2023_key-meter_test_098.mid\n",
      "Prediction: 4\n",
      "100/153: .\\test\\mi2023_key-meter_test_099.mid\n",
      "Prediction: 4\n",
      "101/153: .\\test\\mi2023_key-meter_test_100.mid\n",
      "Prediction: 4\n",
      "102/153: .\\test\\mi2023_key-meter_test_101.mid\n",
      "Prediction: 4\n",
      "103/153: .\\test\\mi2023_key-meter_test_102.mid\n",
      "Prediction: 4\n",
      "104/153: .\\test\\mi2023_key-meter_test_103.mid\n",
      "Prediction: 9\n",
      "105/153: .\\test\\mi2023_key-meter_test_104.mid\n",
      "Prediction: 6\n",
      "106/153: .\\test\\mi2023_key-meter_test_105.mid\n",
      "Prediction: 4\n",
      "107/153: .\\test\\mi2023_key-meter_test_106.mid\n",
      "Prediction: 9\n",
      "108/153: .\\test\\mi2023_key-meter_test_107.mid\n",
      "Prediction: 4\n",
      "109/153: .\\test\\mi2023_key-meter_test_108.mid\n",
      "Prediction: 4\n",
      "110/153: .\\test\\mi2023_key-meter_test_109.mid\n",
      "Prediction: 4\n",
      "111/153: .\\test\\mi2023_key-meter_test_110.mid\n",
      "Prediction: 4\n",
      "112/153: .\\test\\mi2023_key-meter_test_111.mid\n",
      "Prediction: 4\n",
      "113/153: .\\test\\mi2023_key-meter_test_112.mid\n",
      "Prediction: 3\n",
      "114/153: .\\test\\mi2023_key-meter_test_113.mid\n",
      "Prediction: 4\n",
      "115/153: .\\test\\mi2023_key-meter_test_114.mid\n",
      "Prediction: 4\n",
      "116/153: .\\test\\mi2023_key-meter_test_115.mid\n",
      "Prediction: 3\n",
      "117/153: .\\test\\mi2023_key-meter_test_116.mid\n",
      "Prediction: 4\n",
      "118/153: .\\test\\mi2023_key-meter_test_117.mid\n",
      "Prediction: 3\n",
      "119/153: .\\test\\mi2023_key-meter_test_118.mid\n",
      "Prediction: 4\n",
      "120/153: .\\test\\mi2023_key-meter_test_119.mid\n",
      "Prediction: 3\n",
      "121/153: .\\test\\mi2023_key-meter_test_120.mid\n",
      "Prediction: 4\n",
      "122/153: .\\test\\mi2023_key-meter_test_121.mid\n",
      "Prediction: 4\n",
      "123/153: .\\test\\mi2023_key-meter_test_122.mid\n",
      "Prediction: 4\n",
      "124/153: .\\test\\mi2023_key-meter_test_123.mid\n",
      "Prediction: 4\n",
      "125/153: .\\test\\mi2023_key-meter_test_124.mid\n",
      "Prediction: 4\n",
      "126/153: .\\test\\mi2023_key-meter_test_125.mid\n",
      "Prediction: 4\n",
      "127/153: .\\test\\mi2023_key-meter_test_126.mid\n",
      "Prediction: 4\n",
      "128/153: .\\test\\mi2023_key-meter_test_127.mid\n",
      "Prediction: 3\n",
      "129/153: .\\test\\mi2023_key-meter_test_128.mid\n",
      "Prediction: 4\n",
      "130/153: .\\test\\mi2023_key-meter_test_129.mid\n",
      "Prediction: 4\n",
      "131/153: .\\test\\mi2023_key-meter_test_130.mid\n",
      "Prediction: 2\n",
      "132/153: .\\test\\mi2023_key-meter_test_131.mid\n",
      "Prediction: 2\n",
      "133/153: .\\test\\mi2023_key-meter_test_132.mid\n",
      "Prediction: 4\n",
      "134/153: .\\test\\mi2023_key-meter_test_133.mid\n",
      "Prediction: 3\n",
      "135/153: .\\test\\mi2023_key-meter_test_134.mid\n",
      "Prediction: 4\n",
      "136/153: .\\test\\mi2023_key-meter_test_135.mid\n",
      "Prediction: 4\n",
      "137/153: .\\test\\mi2023_key-meter_test_136.mid\n",
      "Prediction: 4\n",
      "138/153: .\\test\\mi2023_key-meter_test_137.mid\n",
      "Prediction: 4\n",
      "139/153: .\\test\\mi2023_key-meter_test_138.mid\n",
      "Prediction: 6\n",
      "140/153: .\\test\\mi2023_key-meter_test_139.mid\n",
      "Prediction: 4\n",
      "141/153: .\\test\\mi2023_key-meter_test_140.mid\n",
      "Prediction: 4\n",
      "142/153: .\\test\\mi2023_key-meter_test_141.mid\n",
      "Prediction: 4\n",
      "143/153: .\\test\\mi2023_key-meter_test_142.mid\n",
      "Prediction: 4\n",
      "144/153: .\\test\\mi2023_key-meter_test_143.mid\n",
      "Prediction: 4\n",
      "145/153: .\\test\\mi2023_key-meter_test_144.mid\n",
      "Prediction: 4\n",
      "146/153: .\\test\\mi2023_key-meter_test_145.mid\n",
      "Prediction: 4\n",
      "147/153: .\\test\\mi2023_key-meter_test_146.mid\n",
      "Prediction: 4\n",
      "148/153: .\\test\\mi2023_key-meter_test_147.mid\n",
      "Prediction: 2\n",
      "149/153: .\\test\\mi2023_key-meter_test_148.mid\n",
      "Prediction: 4\n",
      "150/153: .\\test\\mi2023_key-meter_test_149.mid\n",
      "Prediction: 4\n",
      "151/153: .\\test\\mi2023_key-meter_test_150.mid\n",
      "Prediction: 3\n",
      "152/153: .\\test\\mi2023_key-meter_test_151.mid\n",
      "Prediction: 4\n",
      "153/153: .\\test\\mi2023_key-meter_test_152.mid\n",
      "Prediction: 9\n"
     ]
    }
   ],
   "source": [
    "class MeterPredictionArgs:\n",
    "    datadir = os.path.join('.', 'test')\n",
    "    modeldir = '.' # insert path to our saved model here\n",
    "    \n",
    "args = MeterPredictionArgs()\n",
    "\n",
    "midi_files = glob.glob(os.path.join(args.datadir, \"*.mid\"))\n",
    "midi_files.sort()\n",
    "\n",
    "# Create time and key processors\n",
    "processor_time_sig = RNNTimeSignatureProcessor(os.path.join(args.modeldir, '_model_state_dicts', 'time_signature', 'RNNTimeSignatureModel.pth'))\n",
    "\n",
    "# Prediction\n",
    "for idx, file in enumerate(midi_files):\n",
    "    p = pt.load_performance_midi(Path(file))\n",
    "    note_array = p.note_array()\n",
    "    note_sequence = np.array(list(zip(note_array['pitch'], note_array['onset_sec'], note_array['duration_sec'], note_array['velocity'])))\n",
    "\n",
    "    time_signature_changes = processor_time_sig.process(note_sequence)\n",
    "\n",
    "    length = note_sequence[-1][1] + note_sequence[-1][2]\n",
    "\n",
    "    last_onset, last_ts_num = time_signature_changes[0]\n",
    "    durations = {}\n",
    "    for onset, ts_num in time_signature_changes[1:]:\n",
    "        if last_ts_num not in durations.keys():\n",
    "            durations[last_ts_num] = 0\n",
    "        durations[last_ts_num] += onset - last_onset\n",
    "        last_onset = onset\n",
    "        last_ts_num = ts_num\n",
    "    if last_ts_num not in durations.keys():\n",
    "        durations[last_ts_num] = 0\n",
    "    durations[last_ts_num] += length - last_onset\n",
    "\n",
    "    best_duration, best_ts_num = 0, 0\n",
    "    for ts_num, duration in durations.items():\n",
    "        if duration > best_duration:\n",
    "            best_duration = duration\n",
    "            best_ts_num = ts_num\n",
    "\n",
    "    print(f\"{str(idx + 1)}/{str(len(midi_files))}: {file}\")\n",
    "    print(\"Prediction: \" + str(best_ts_num))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:53:44.715630700Z",
     "start_time": "2024-01-08T13:49:37.995735400Z"
    }
   },
   "id": "64daa6c5bb647d32"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion of meter estimation\n",
    "\n",
    "With this model, we were able to achieve an f-score of about 0.47, but again this was done on some pieces of the training set. This might not seem like much, but when we applied it so the test set, we reached a score of 0.572 on the leaderboard, just below the current best meter estimation (0.575 as of January 8th).\n",
    "\n",
    "Now, we have to take a look at the tempo estimation!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7c44f5232f077d7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tempo\n",
    "\n",
    "To calculate the tempo, we make use of the hidden markov model (HMM) presented in the lecture with some slight alterations."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9134a36c5e5e84a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Subbeats from durations\n",
    "\n",
    "Initially, the HMMs tried every other option with a sub beat count of 2 or 3, but we observed a pattern in many of the train pieces: Very often, a note is played for the duration of a beat, while other notes (mostly higher notes) are played every sub beat. So we could generate a histogram of note durations, search for peaks, and then see if the first two peaks have a factor close to 2 or 3. In this case, only that option is considered when trying out different configurations with the HMM.\n",
    "\n",
    "To show that this is indeed the case for some pieces, we will now see some pieces that show this pattern:\n",
    "\n",
    "![3 subbeats per beat.](img/Roll1.png)\n",
    "\n",
    "![2 subbeats per beat.](img/Roll2.png)\n",
    "\n",
    "![2 subbeats per beat.](img/Roll3.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1caf19f05bc5026"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "def subbeats_from_durations(note_array: np.ndarray):\n",
    "    durations = note_array[\"duration_sec\"]\n",
    "    hist, bins = np.histogram(durations, bins=100)\n",
    "\n",
    "    peaks, _ = find_peaks(hist, prominence=20)\n",
    "\n",
    "    if len(peaks) > 1:\n",
    "        candidate = bins[peaks[1]] / bins[peaks[0]]\n",
    "        if 1.9 < candidate < 2.1:\n",
    "            return [2]\n",
    "        if 2.9 < candidate < 3.1:\n",
    "            return [3]\n",
    "    return [2, 3]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:53:44.739566100Z",
     "start_time": "2024-01-08T13:53:44.719620Z"
    }
   },
   "id": "6b02c516f2847d9b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tempi from inter onset intervals\n",
    "\n",
    "Calculating the possible tempi by using autocorrelation causes many different tempi to be considered, and most of the time their values are too 'clean', like 120.0, 240.0 or 43.43434343. We try to use the histogram of inter onset intervals (IOIs) to detect how long a beat is by finding the first valid peak and calculating the beats per minute. Then, we calculate a couple of multipliers to add to the tempi list, precisely 1, 2, 4, and 8 as the piece might have a lot of 16th notes although it is written in 4/4, for example.\n",
    "\n",
    "The following histograms should support our claims:\n",
    "\n",
    "![A piece with 58.9 BPM.](img/IOI1.png)\n",
    "\n",
    "In this case, the actual tempo was 58.9 BPM.\n",
    "From this, we calculate that there are 1.0187 beats per second and 0.982 seconds per beat.\n",
    "The histogram shows a peak at about 0.12 seconds per beat, which is very close to 0.982 when multiplied by 8.\n",
    "\n",
    "![A piece with 115.8 BPM.](img/IOI2.png)\n",
    "\n",
    "Here, the tempo was 115.8 BPM, which are 1.93 beats per second and 0.518 seconds per beat.\n",
    "When divided by 2, the resulting 0.259 are close to the histrogram's peak."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f3056e6c2aed4e2"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def tempi_from_iois(note_array: np.ndarray, min_tempo: float, max_tempo: float):\n",
    "    IOIs = np.diff(np.sort(note_array[\"onset_sec\"]))\n",
    "    hist, bins = np.histogram(IOIs, bins=100)\n",
    "\n",
    "    valid_from = 0\n",
    "    for i in range(len(bins)):\n",
    "        if bins[i] >= 1 / 16:\n",
    "            valid_from = i\n",
    "            break\n",
    "\n",
    "    new_hist = []\n",
    "    new_labels = []\n",
    "    for i in range(valid_from - 1, len(hist) - 1):\n",
    "        new_hist.append((hist[i-1] + hist[i] + hist[i+1]) / 3)\n",
    "        new_labels.append((bins[i+1] + bins[i]) / 2)\n",
    "\n",
    "    peaks, _ = find_peaks(new_hist, prominence=5)\n",
    "\n",
    "    if len(peaks) == 0:\n",
    "        return []\n",
    "\n",
    "    beat_duration = new_labels[peaks[0]]\n",
    "    beats_per_minute = 60 / beat_duration\n",
    "    tempi = []\n",
    "    for i in range(4):\n",
    "        tempo = beats_per_minute / (2 ** i)\n",
    "        if min_tempo < tempo < max_tempo:\n",
    "            tempi.append(tempo)\n",
    "    return tempi"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:53:54.918394100Z",
     "start_time": "2024-01-08T13:53:54.904431300Z"
    }
   },
   "id": "dfe86d76e163e259"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hidden Markov Model\n",
    "\n",
    "Now, we just take the given HMM from the lecture which was provided via Baseline_Meter.py."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a53dd3c4f8642f4f"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "from typing import Tuple, Iterable\n",
    "\n",
    "from hiddenmarkov import ConstantTransitionModel, ObservationModel\n",
    "\n",
    "FRAMERATE = 16\n",
    "\n",
    "\n",
    "class MeterObservationModel(ObservationModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        states: int = 20,\n",
    "        downbeat_idx: Iterable = [0],\n",
    "        beat_idx: Iterable = [50],\n",
    "        subbeat_idx: Iterable = [25],\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.states = states\n",
    "        # observation 1 = note onset present, 0 = nothing present\n",
    "        self.probabilities = np.ones((2, states)) / 100\n",
    "        self.probabilities[0, :] = 0.99\n",
    "        for idx in subbeat_idx:\n",
    "            self.probabilities[:, idx] = [0.5, 0.5]\n",
    "        for idx in beat_idx:\n",
    "            self.probabilities[:, idx] = [0.3, 0.7]\n",
    "        for idx in downbeat_idx:\n",
    "            self.probabilities[:, idx] = [0.1, 0.9]\n",
    "        self.db = downbeat_idx\n",
    "        self.b = beat_idx\n",
    "        self.sb = subbeat_idx\n",
    "\n",
    "    def get_beat_states(self, state_sequence: np.ndarray) -> np.ndarray:\n",
    "        state_encoder = np.zeros_like(state_sequence)\n",
    "        for i, state in enumerate(state_sequence):\n",
    "            if state in self.sb:\n",
    "                state_encoder[i] = 1\n",
    "            if state in self.b:\n",
    "                state_encoder[i] = 2\n",
    "            if state in self.db:\n",
    "                state_encoder[i] = 3\n",
    "        return state_encoder\n",
    "\n",
    "    def __call__(self, observation: np.ndarray) -> np.ndarray:\n",
    "        if not self.use_log_probabilities:\n",
    "            return self.probabilities[observation, :]\n",
    "        else:\n",
    "            return np.log(self.probabilities[observation, :])\n",
    "\n",
    "\n",
    "def getTransitionMatrix(\n",
    "    states: int,\n",
    "    distribution: Iterable = [0.1, 0.8, 0.1],\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute transition Matrix\n",
    "    \"\"\"\n",
    "    if states == 1:\n",
    "        raise ValueError(\"The number of states should be > 1\")\n",
    "    transition_matrix = (\n",
    "        np.eye(states, k=0) * distribution[0]\n",
    "        + np.eye(states, k=1) * distribution[1]\n",
    "        + np.eye(states, k=2) * distribution[2]\n",
    "        + np.ones((states, states)) / 1e7\n",
    "    )\n",
    "\n",
    "    transition_matrix[-2, 0] = distribution[2]\n",
    "    transition_matrix[-1, 0] = distribution[2] + distribution[1]\n",
    "\n",
    "    return transition_matrix\n",
    "\n",
    "\n",
    "def createHMM(\n",
    "    tempo: float = 50,\n",
    "    frame_rate: int = FRAMERATE,  # frames_per_beat\n",
    "    beats_per_measure: int = 4,\n",
    "    subbeats_per_beat: int = 2,\n",
    ") -> Tuple[MeterObservationModel, ConstantTransitionModel]:\n",
    "    frames_per_beat = 60 / tempo * frame_rate\n",
    "    frames_per_measure = frames_per_beat * beats_per_measure\n",
    "    states = int(frames_per_measure)\n",
    "    downbeat_idx = [0]\n",
    "    beat_idx = [int(states / beats_per_measure * k) for k in range(beats_per_measure)]\n",
    "    subbeat_idx = [\n",
    "        int(states / (beats_per_measure * subbeats_per_beat) * k)\n",
    "        for k in range(beats_per_measure * subbeats_per_beat)\n",
    "    ]\n",
    "\n",
    "    observation_model = MeterObservationModel(\n",
    "        states=states,\n",
    "        downbeat_idx=downbeat_idx,\n",
    "        beat_idx=beat_idx,\n",
    "        subbeat_idx=subbeat_idx,\n",
    "    )\n",
    "\n",
    "    transition_matrix = getTransitionMatrix(states)\n",
    "    transition_model = ConstantTransitionModel(transition_matrix)\n",
    "\n",
    "    return observation_model, transition_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:53:58.971108200Z",
     "start_time": "2024-01-08T13:53:58.909222100Z"
    }
   },
   "id": "207a951430649f0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tempo estimation\n",
    "\n",
    "The method to finally estimate the tempo is nearly identical to the one we received initially, but it now makes use of the sub beat extraction from durations and the tempo candidates extracted from the IOIs. When there are no tempo candidates, we fall back to the autocorrelation again."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c906ba918738020"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from partitura.utils.misc import PathLike\n",
    "from meter_estimation_utils import get_frames_chordify, compute_autocorrelation\n",
    "from hiddenmarkov import HMM\n",
    "\n",
    "\n",
    "def estimate_tempo(\n",
    "    filename: PathLike,\n",
    "    beats_per_measure: int,\n",
    "    framerate: int = FRAMERATE,\n",
    "    frame_threshold: float = 0.0,\n",
    "    chord_spread_time: float = 1 / 12,\n",
    "    max_tempo: float = 250,\n",
    "    min_tempo: float = 30,\n",
    ") -> float:\n",
    "    # get note array\n",
    "    performance = pt.load_performance_midi(filename)\n",
    "    note_array = performance.note_array()\n",
    "    subbeats_per_beat = subbeats_from_durations(note_array)\n",
    "    tempi = tempi_from_iois(note_array, min_tempo, max_tempo)\n",
    "    if len(tempi) == 0:\n",
    "        tempi = \"auto\"\n",
    "\n",
    "    frames = get_frames_chordify(\n",
    "        note_array=note_array,\n",
    "        framerate=framerate,\n",
    "        chord_spread_time=chord_spread_time,\n",
    "        threshold=frame_threshold,\n",
    "    )\n",
    "\n",
    "    if tempi == \"auto\":\n",
    "        autocorr = compute_autocorrelation(frames)\n",
    "        beat_period, _ = find_peaks(autocorr[1:], prominence=None)\n",
    "        tempi = 60 * framerate / (beat_period + 1)\n",
    "        tempi = tempi[np.logical_and(tempi <= max_tempo, tempi >= min_tempo)]\n",
    "\n",
    "        if len(tempi) == 0:\n",
    "            tempi = np.linspace(min_tempo, max_tempo, 10)\n",
    "\n",
    "    likelihoods = []\n",
    "\n",
    "    for sbpb in subbeats_per_beat:\n",
    "        for tempo in tempi:\n",
    "            observation_model, transition_model = createHMM(\n",
    "                tempo=tempo,\n",
    "                frame_rate=framerate,\n",
    "                beats_per_measure=beats_per_measure,\n",
    "                subbeats_per_beat=sbpb,\n",
    "            )\n",
    "\n",
    "            hmm = HMM(\n",
    "                observation_model=observation_model,\n",
    "                transition_model=transition_model,\n",
    "            )\n",
    "\n",
    "            frames[frames < 1.0] = 0\n",
    "            frames[frames >= 1.0] = 1\n",
    "\n",
    "            observations = np.array(frames, dtype=int)\n",
    "            _, log_lik = hmm.find_best_sequence(observations)\n",
    "\n",
    "            likelihoods.append((sbpb, tempo, log_lik))\n",
    "\n",
    "    likelihoods = np.array(likelihoods)\n",
    "\n",
    "    best_result = likelihoods[likelihoods[:, 2].argmax()]\n",
    "\n",
    "    best_tempo = best_result[1]\n",
    "\n",
    "    return best_tempo\n",
    "\n",
    "def process_file(\n",
    "    mfn: PathLike, file_to_fix: Dict[str, Tuple[float, float]],\n",
    ") -> Tuple[str, int, float]:\n",
    "    piece: str = os.path.basename(mfn)\n",
    "    meter = int(file_to_fix[piece][0])\n",
    "    predicted_tempo: float = estimate_tempo(filename=mfn, beats_per_measure=meter)\n",
    "\n",
    "    return (\n",
    "        piece,\n",
    "        meter,\n",
    "        predicted_tempo,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:54:00.283668300Z",
     "start_time": "2024-01-08T13:54:00.257526400Z"
    }
   },
   "id": "a2bcddaf0f04a2c3"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "def load_submission(fn: str) -> dict:\n",
    "    gt = np.loadtxt(\n",
    "        fn,\n",
    "        dtype=str,\n",
    "        delimiter=\",\",\n",
    "        comments=\"//\",\n",
    "    )\n",
    "\n",
    "    if gt.shape[1] > 3:\n",
    "        submission = dict([(g[0], (int(g[2]), float(g[4]))) for g in gt])\n",
    "    else:\n",
    "        submission = dict([(g[0], (int(g[1]), float(g[2]))) for g in gt])\n",
    "\n",
    "    return submission"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T13:54:00.956127Z",
     "start_time": "2024-01-08T13:54:00.936152400Z"
    }
   },
   "id": "12863d6a117f2bfe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/153 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class TempoEstimationArgs:\n",
    "    datadir = os.path.join('.', 'test') # insert path to your dataset here\n",
    "    outfile = os.path.join('.', 'result.txt') # insert path to your out file with meters (and dummy tempos) here\n",
    "\n",
    "\n",
    "args = TempoEstimationArgs()\n",
    "\n",
    "\n",
    "# Adapt this part as needed!\n",
    "midi_files = glob.glob(os.path.join(args.datadir, \"*.mid\"))\n",
    "midi_files.sort()\n",
    "\n",
    "file_to_fix = load_submission(args.outfile)\n",
    "\n",
    "# Parallel processing with concurrent.futures\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    # Using executor.map for parallel processing\n",
    "    results_ = list(\n",
    "        tqdm(\n",
    "            executor.map(\n",
    "                process_file,\n",
    "                midi_files,\n",
    "                len(midi_files) * [file_to_fix],\n",
    "            ),\n",
    "            total=len(midi_files),\n",
    "        )\n",
    "    )\n",
    "\n",
    "results = [res[:3] for res in results_]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-08T13:55:35.471203300Z"
    }
   },
   "id": "5ec74a69c834a8d2"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a49baf21b5eb7309"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "Calculating the tempo in this manner scored us a tempo error of just 9.691 with the test set, which ranks us 3rd on the leaderboard (as of January 8th). Combined with the meter accuracy of 0.572, we are more than happy with our results compared to the others we see on the scoreboard. The tempo estimation can surely be enhanced further, either by improving the HMM or using another approach altogether, like an RNN again, but for this instance we think that our output is sufficient given the simplicity of its calculation as well as its dependence on the (mediocre) accuracy of the meter numerator."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "737b8ae65102f364"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "79c90ddfdeb8a6b0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
